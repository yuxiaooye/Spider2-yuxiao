{
    "table_name": "detail_desc_text_2021",
    "table_fullname": "spider2-public-data.patentsview.detail_desc_text_2021",
    "column_names": [
        "patent_id",
        "text",
        "length"
    ],
    "column_types": [
        "STRING",
        "STRING",
        "INT64"
    ],
    "nested_column_names": [
        "patent_id",
        "text",
        "length"
    ],
    "nested_column_types": [
        "STRING",
        "STRING",
        "INT64"
    ],
    "description": [
        null,
        null,
        null
    ],
    "sample_rows": [
        {
            "patent_id": "10937052",
            "text": "DETAILED DESCRIPTION\n\nEmbodiments are described herein according to the following outline:1.0. General Overview2.0. Operating Environment2.1. Host Devices2.2. Client Devices2.3. Client Device Applications2.4. Data Server System2.5. Data Ingestion2.5.1. Input2.5.2. Parsing2.5.3. Indexing2.6. Query Processing2.7. Field Extraction2.8. Cloud-Based System Overview2.9. Searching Externally Archived Data2.9.1. ERP Process Features3.0. Geographic Positioning Subsystem3.1. Geographic Positioning Analyzer3.2. Geographic Positioning Methods3.3 ExamplesSpecific embodiments of the invention will now be described in detail with reference to the accompanying figures. Like elements in the various figures are denoted by like reference numerals for consistency.\n\nIn the following detailed description of embodiments of the invention, numerous specific details are set forth in order to provide a more thorough understanding of the invention. However, it will be apparent to one of ordinary skill in the art that the invention may be practiced without these specific details. In other instances, well-known features have not been described in detail to avoid unnecessarily complicating the description.\n\nThroughout the application, ordinal numbers (e.g., first, second, third, etc.) may be used as an adjective for an element (i.e., any noun in the application). The use of ordinal numbers is not to imply or create any particular ordering of the elements nor to limit any element to being only a single element unless expressly disclosed, such as by the use of the terms \u201cbefore\u201d, \u201cafter\u201d, \u201csingle\u201d, and other such terminology. Rather, the use of ordinal numbers is to distinguish between the elements. By way of an example, a first element is distinct from a second element, and the first element may encompass more than one element and succeed (or precede) the second element in an ordering of elements.\n\nExecutive Summary\n\nIn general, embodiments of the invention involve using raw machine data (e.g., wireless router logs) to determine a succession of geographic positions of customers in the vicinity of retail locales. Interactions between mobile devices of customers and network devices at the retail locale may be tracked and logged as the customers move within various zones of the retail locale. Using the geographic positions alone, or in combination with data from other sources (e.g., reward/loyalty systems, point-of-sale (POS) devices, inventory systems, sensors, promotion redemption systems, etc.), various metrics may be calculated and correlations may be performed to support powerful retail analytics. Examples of such metrics may include: waiting times at sales registers, walk-by sales conversion rates, amount of time spent at the retail locale, processing time to redeem promotions, etc. The various metrics may be used to predict and/or measure the operational impact of promotions.\n\n1.0. General Overview\n\nModern data centers and other computing environments can comprise anywhere from a few host computer systems to thousands of systems configured to process data, service requests from remote clients, and perform numerous other computational tasks. During operation, various components within these computing environments often generate significant volumes of machine-generated data. For example, machine data is generated by various components in the information technology (IT) environments, such as servers, sensors, routers, mobile devices, Internet of Things (IoT) devices, etc. Machine-generated data can include system logs, network packet data, sensor data, application program data, error logs, stack traces, system performance data, etc. In general, machine-generated data can also include performance data, diagnostic information, and many other types of data that can be analyzed to diagnose performance problems, monitor user interactions, and to derive other insights.\n\nA number of tools are available to analyze machine data, that is, machine-generated data. In order to reduce the size of the potentially vast amount of machine data that may be generated, many of these tools typically pre-process the data based on anticipated data-analysis needs. For example, pre-specified data items may be extracted from the machine data and stored in a database to facilitate efficient retrieval and analysis of those data items at search time. However, the rest of the machine data typically is not saved and discarded during pre-processing. As storage capacity becomes progressively cheaper and more plentiful, there are fewer incentives to discard these portions of machine data and many reasons to retain more of the data.\n\nThis plentiful storage capacity is presently making it feasible to store massive quantities of minimally processed machine data for later retrieval and analysis. In general, storing minimally processed machine data and performing analysis operations at search time can provide greater flexibility because it enables an analyst to search all of the machine data, instead of searching only a pre-specified set of data items. This may enable an analyst to investigate different aspects of the machine data that previously were unavailable for analysis.\n\nHowever, analyzing and searching massive quantities of machine data presents a number of challenges. For example, a data center, servers, or network appliances may generate many different types and formats of machine data (e.g., system logs, network packet data (e.g., wire data, etc.), sensor data, application program data, error logs, stack traces, system performance data, operating system data, virtualization data, etc.) from thousands of different components, which can collectively be very time-consuming to analyze. In another example, mobile devices may generate large amounts of information relating to data accesses, application performance, operating system performance, network performance, etc. There can be millions of mobile devices that report these types of information.\n\nThese challenges can be addressed by using an event-based data intake and query system, such as the SPLUNK\u00ae ENTERPRISE system developed by Splunk Inc. of San Francisco, Calif. The SPLUNK\u00ae ENTERPRISE system is the leading platform for providing real-time operational intelligence that enables organizations to collect, index, and search machine-generated data from various websites, applications, servers, networks, and mobile devices that power their businesses. The SPLUNK\u00ae ENTERPRISE system is particularly useful for analyzing data which is commonly found in system log files, network data, and other data input sources. Although many of the techniques described herein are explained with reference to a data intake and query system similar to the SPLUNK\u00ae ENTERPRISE system, these techniques are also applicable to other types of data systems.\n\nIn the SPLUNK\u00ae ENTERPRISE system, machine-generated data are collected and stored as \u201cevents\u201d. An event comprises a portion of the machine-generated data and is associated with a specific point in time. For example, events may be derived from \u201ctime series data,\u201d where the time series data comprises a sequence of data points (e.g., performance measurements from a computer system, etc.) that are associated with successive points in time. In general, each event can be associated with a timestamp that is derived from the raw data in the event, determined through interpolation between temporally proximate events having known timestamps, or determined based on other configurable rules for associating timestamps with events, etc.\n\nIn some instances, machine data can have a predefined format, where data items with specific data formats are stored at predefined locations in the data. For example, the machine data may include data stored as fields in a database table. In other instances, machine data may not have a predefined format, that is, the data is not at fixed, predefined locations, but the data does have repeatable patterns and is not random. This means that some machine data can comprise various data items of different data types and that may be stored at different locations within the data. For example, when the data source is an operating system log, an event can include one or more lines from the operating system log containing raw data that includes different types of performance and diagnostic information associated with a specific point in time.\n\nExamples of components which may generate machine data from which events can be derived include, but are not limited to, web servers, application servers, databases, firewalls, routers, operating systems, and software applications that execute on computer systems, mobile devices, sensors, Internet of Things (IoT) devices, etc. The data generated by such data sources can include, for example and without limitation, server log files, activity log files, configuration files, messages, network packet data, performance measurements, sensor measurements, etc.\n\nThe SPLUNK\u00ae ENTERPRISE system uses flexible schema to specify how to extract information from the event data. A flexible schema may be developed and redefined as needed. Note that a flexible schema may be applied to event data \u201con the fly,\u201d when it is needed (e.g., at search time, index time, ingestion time, etc.). When the schema is not applied to event data until search time it may be referred to as a \u201clate-binding schema.\u201d\n\nDuring operation, the SPLUNK\u00ae ENTERPRISE system starts with raw input data (e.g., one or more system logs, streams of network packet data, sensor data, application program data, error logs, stack traces, system performance data, etc.). The system divides this raw data into blocks (e.g., buckets of data, each associated with a specific time frame, etc.), and parses the raw data to produce timestamped events. The system stores the timestamped events in a data store. The system enables users to run queries against the stored data to, for example, retrieve events that meet criteria specified in a query, such as containing certain keywords or having specific values in defined fields. As used herein throughout, data that is part of an event is referred to as \u201cevent data\u201d. In this context, the term \u201cfield\u201d refers to a location in the event data containing one or more values for a specific data item. As will be described in more detail herein, the fields are defined by extraction rules (e.g., regular expressions) that derive one or more values from the portion of raw machine data in each event that has a particular field specified by an extraction rule. The set of values so produced are semantically-related (such as IP address), even though the raw machine data in each event may be in different formats (e.g., semantically-related values may be in different positions in the events derived from different sources).\n\nAs noted above, the SPLUNK\u00ae ENTERPRISE system utilizes a late-binding schema to event data while performing queries on events. One aspect of a late-binding schema is applying \u201cextraction rules\u201d to event data to extract values for specific fields during search time. More specifically, the extraction rules for a field can include one or more instructions that specify how to extract a value for the field from the event data. An extraction rule can generally include any type of instruction for extracting values from data in events. In some cases, an extraction rule comprises a regular expression where a sequence of characters forms a search pattern, in which case the rule is referred to as a \u201cregex rule.\u201d The system applies the regex rule to the event data to extract values for associated fields in the event data by searching the event data for the sequence of characters defined in the regex rule.\n\nIn the SPLUNK\u00ae ENTERPRISE system, a field extractor may be configured to automatically generate extraction rules for certain field values in the events when the events are being created, indexed, or stored, or possibly at a later time. Alternatively, a user may manually define extraction rules for fields using a variety of techniques. In contrast to a conventional schema for a database system, a late-binding schema is not defined at data ingestion time. Instead, the late-binding schema can be developed on an ongoing basis until the time a query is actually executed. This means that extraction rules for the fields in a query may be provided in the query itself, or may be located during execution of the query. Hence, as a user learns more about the data in the events, the user can continue to refine the late-binding schema by adding new fields, deleting fields, or modifying the field extraction rules for use the next time the schema is used by the system. Because the SPLUNK\u00ae ENTERPRISE system maintains the underlying raw data and uses late-binding schema for searching the raw data, it enables a user to continue investigating and learn valuable insights about the raw data.\n\nIn some embodiments, a common field name may be used to reference two or more fields containing equivalent data items, even though the fields may be associated with different types of events that possibly have different data formats and different extraction rules. By enabling a common field name to be used to identify equivalent fields from different types of events generated by disparate data sources, the system facilitates use of a \u201ccommon information model\u201d (CIM) across the disparate data sources (further discussed with respect toFIG. 5).\n\n2.0. Operating Environment\n\nFIG. 1illustrates a networked computer system (100) in which an embodiment may be implemented. Those skilled in the art would understand thatFIG. 1represents one example of a networked computer system and other embodiments may use different arrangements.\n\nThe networked computer system (100) comprises one or more computing devices. These one or more computing devices comprise any combination of hardware and software configured to implement the various logical components described herein. For example, the one or more computing devices may include one or more memories that store instructions for implementing the various components described herein, one or more hardware processors configured to execute the instructions stored in the one or more memories, and various data repositories in the one or more memories for storing data structures utilized and manipulated by the various components.\n\nIn an embodiment, one or more client devices (102) are coupled to one or more host devices (106) and a data intake and query system (108) via one or more networks (104). Networks (104) broadly represent one or more LANs, WANs, cellular networks (e.g., LTE, HSPA, 3G, and other cellular technologies), and/or networks using any of wired, wireless, terrestrial microwave, or satellite links, and may include the public Internet.\n\n2.1. Host Devices\n\nIn the illustrated embodiment, a system (100) includes one or more host devices (106). Host devices (106) may broadly include any number of computers, virtual machine instances, and/or data centers that are configured to host or execute one or more instances of host applications (114). In general, a host device (106) may be involved, directly or indirectly, in processing requests received from client devices (102). Each host device (106) may comprise, for example, one or more of a network device, a web server, an application server, a database server, etc. A collection of host devices (106) may be configured to implement a network-based service. For example, a provider of a network-based service may configure one or more host devices (106) and host applications (114) (e.g., one or more web servers, application servers, database servers, etc.) to collectively implement the network-based application.\n\nIn general, client devices (102) communicate with one or more host applications (114) to exchange information. The communication between a client device (102) and a host application (114) may, for example, be based on the Hypertext Transfer Protocol (HTTP) or any other network protocol. Content delivered from the host application (114) to a client device (102) may include, for example, HTML documents, media content, etc. The communication between a client device (102) and host application (114) may include sending various requests and receiving data packets. For example, in general, a client device (102) or application running on a client device may initiate communication with a host application (114) by making a request for a specific resource (e.g., based on an HTTP request), and the application server may respond with the requested content stored in one or more response packets.\n\nIn the illustrated embodiment, one or more of host applications (114) may generate various types of performance data during operation, including event logs, network data, sensor data, and other types of machine-generated data. For example, a host application (114) comprising a web server may generate one or more web server logs in which details of interactions between the web server and any number of client devices (102) is recorded. As another example, a host device (106) comprising a router may generate one or more router logs that record information related to network traffic managed by the router. As yet another example, a host application (114) comprising a database server may generate one or more logs that record information related to requests sent from other host applications (114) (e.g., web servers or application servers) for data managed by the database server.\n\n2.2. Client Devices\n\nClient devices (102) ofFIG. 1represent any computing device capable of interacting with one or more host devices (106) via a network (104). Examples of client devices (102) may include, without limitation, smart phones, tablet computers, handheld computers, wearable devices, laptop computers, desktop computers, servers, portable media players, gaming devices, and so forth. In general, a client device (102) can provide access to different content, for instance, content provided by one or more host devices (106), etc. Each client device (102) may comprise one or more client applications (110), described in more detail in a separate section hereinafter.\n\n2.3. Client Device Applications\n\nIn an embodiment, each client device (102) may host or execute one or more client applications (110) that are capable of interacting with one or more host devices (106) via one or more networks (104). For instance, a client application (110) may be or comprise a web browser that a user may use to navigate to one or more websites or other resources provided by one or more host devices (106). As another example, a client application (110) may comprise a mobile application or \u201capp.\u201d For example, an operator of a network-based service hosted by one or more host devices (106) may make available one or more mobile apps that enable users of client devices (102) to access various resources of the network-based service. As yet another example, client applications (110) may include background processes that perform various operations without direct interaction from a user. A client application (110) may include a \u201cplug-in\u201d or \u201cextension\u201d to another application, such as a web browser plug-in or extension.\n\nIn an embodiment, a client application (110) may include a monitoring component (112). At a high level, the monitoring component (112) comprises a software component or other logic that facilitates generating performance data related to a client device's operating state, including monitoring network traffic sent and received from the client device and collecting other device and/or application-specific information. Monitoring component (112) may be an integrated component of a client application (110), a plug-in, an extension, or any other type of add-on component. Monitoring component (112) may also be a stand-alone process.\n\nIn one embodiment, a monitoring component (112) may be created when a client application (110) is developed, for example, by an application developer using a software development kit (SDK). The SDK may include custom monitoring code that can be incorporated into the code implementing a client application (110). When the code is converted to an executable application, the custom code implementing the monitoring functionality can become part of the application itself.\n\nIn some cases, an SDK or other code for implementing the monitoring functionality may be offered by a provider of a data intake and query system, such as a system (108). In such cases, the provider of the system (108) can implement the custom code so that performance data generated by the monitoring functionality is sent to the system (108) to facilitate analysis of the performance data by a developer of the client application or other users.\n\nIn an embodiment, the custom monitoring code may be incorporated into the code of a client application (110) in a number of different ways, such as the insertion of one or more lines in the client application code that call or otherwise invoke the monitoring component (112). As such, a developer of a client application (110) can add one or more lines of code into the client application (110) to trigger the monitoring component (112) at desired points during execution of the application. Code that triggers the monitoring component may be referred to as a monitor trigger. For instance, a monitor trigger may be included at or near the beginning of the executable code of the client application (110) such that the monitoring component (112) is initiated or triggered as the application is launched, or included at other points in the code that correspond to various actions of the client application, such as sending a network request or displaying a particular interface.\n\nIn an embodiment, the monitoring component (112) may monitor one or more aspects of network traffic sent and/or received by a client application (110). For example, the monitoring component (112) may be configured to monitor data packets transmitted to and/or from one or more host applications (114). Incoming and/or outgoing data packets can be read or examined to identify network data contained within the packets, for example, and other aspects of data packets can be analyzed to determine a number of network performance statistics. Monitoring network traffic may enable information to be gathered particular to the network performance associated with a client application (110) or set of applications.\n\nIn an embodiment, network performance data refers to any type of data that indicates information about the network and/or network performance. Network performance data may include, for instance, a URL requested, a connection type (e.g., HTTP, HTTPS, etc.), a connection start time, a connection end time, an HTTP status code, request length, response length, request headers, response headers, connection status (e.g., completion, response time(s), failure, etc.), and the like. Upon obtaining network performance data indicating performance of the network, the network performance data can be transmitted to a data intake and query system (108) for analysis.\n\nUpon developing a client application (110) that incorporates a monitoring component (112), the client application (110) can be distributed to client devices (102). Applications generally can be distributed to client devices (102) in any manner, or they can be pre-loaded. In some cases, the application may be distributed to a client device (102) via an application marketplace or other application distribution system. For instance, an application marketplace or other application distribution system might distribute the application to a client device based on a request from the client device to download the application.\n\nExamples of functionality that enables monitoring performance of a client device are described in U.S. patent application Ser. No. 14/524,748, entitled \u201cUTILIZING PACKET HEADERS TO MONITOR NETWORK TRAFFIC IN ASSOCIATION WITH A CLIENT DEVICE\u201d, filed on 27 Oct. 2014, and which is hereby incorporated by reference in its entirety for all purposes.\n\nIn an embodiment, the monitoring component (112) may also monitor and collect performance data related to one or more aspects of the operational state of a client application (110) and/or client device (102). For example, a monitoring component (112) may be configured to collect device performance information by monitoring one or more client device operations, or by making calls to an operating system and/or one or more other applications executing on a client device (102) for performance information. Device performance information may include, for instance, a current wireless signal strength of the device, a current connection type and network carrier, current memory performance information, a geographic location of the device, a device orientation, and any other information related to the operational state of the client device.\n\nIn an embodiment, the monitoring component (112) may also monitor and collect other device profile information including, for example, a type of client device, a manufacturer and model of the device, versions of various software applications installed on the device, and so forth.\n\nIn general, a monitoring component (112) may be configured to generate performance data in response to a monitor trigger in the code of a client application (110) or other triggering application event, as described above, and to store the performance data in one or more data records. Each data record, for example, may include a collection of field-value pairs, each field-value pair storing a particular item of performance data in association with a field for the item. For example, a data record generated by a monitoring component (112) may include a \u201cnetworkLatency\u201d field (not shown in the Figure) in which a value is stored. This field indicates a network latency measurement associated with one or more network requests. The data record may include a \u201cstate\u201d field to store a value indicating a state of a network connection, and so forth for any number of aspects of collected performance data.\n\n2.4. Data Server System\n\nFIG. 2depicts a block diagram of an exemplary data intake and query system (108), similar to the SPLUNK\u00ae ENTERPRISE system. System (108) includes one or more forwarders (204) that receive data from a variety of input data sources (202), and one or more indexers (206) that process and store the data in one or more data stores (208). These forwarders and indexers can comprise separate computer systems, or may alternatively comprise separate processes executing on one or more computer systems.\n\nEach data source (202) broadly represents a distinct source of data that can be consumed by a system (108). Examples of a data source (202) include, without limitation, data files, directories of files, data sent over a network, event logs, registries, etc.\n\nDuring operation, the forwarders (204) identify which indexers (206) receive data collected from a data source (202) and forward the data to the appropriate indexers. Forwarders (204) can also perform operations on the data before forwarding, including removing extraneous data, detecting timestamps in the data, parsing data, indexing data, routing data based on criteria relating to the data being routed, and/or performing other data transformations.\n\nIn an embodiment, a forwarder (204) may comprise a service accessible to client devices (102) and host devices (106) via a network (104). For example, one type of forwarder (204) may be capable of consuming vast amounts of real-time data from a potentially large number of client devices (102) and/or host devices (106). The forwarder (204) may, for example, comprise a computing device which implements multiple data pipelines or \u201cqueues\u201d to handle forwarding of network data to indexers (206). A forwarder (204) may also perform many of the functions that are performed by an indexer. For example, a forwarder (204) may perform keyword extractions on raw data or parse raw data to create events. A forwarder (204) may generate time stamps for events. Additionally or alternatively, a forwarder (204) may perform routing of events to indexers. Data store (208) may contain events derived from machine data from a variety of sources all pertaining to the same component in an IT environment, and this data may be produced by the machine in question or by other components in the IT environment. All or a portion of the data store (208) may be referred to as a field-searchable data store. In one or more embodiments, field-searchable means that the fields of the raw machine data may be searched using extraction rules, as described below. The field-searchable data store may store event logs having events. Events in the event logs may be ordered according to the time of the event (e.g., by appending new events to the end of the event log). The event logs with corresponding events may be partitioned into buckets, wherein each bucket stores events corresponding to a specific time range. In one embodiment, the field searchable data store is implemented in indexers (206) where events are stored in buckets. In other embodiments, events may be stored in any data store (208) capable of storing events.\n\nIn one or more embodiments of the invention, data store (208) is any type of storage unit and/or device (e.g., a file system, database, collection of tables, or any other storage mechanism) for storing data. Further, data store (208) may include multiple different storage units and/or devices. The multiple different storage units and/or devices may or may not be of the same type or located at the same physical site.\n\n2.5. Data Ingestion\n\nFIG. 3depicts a flow chart illustrating an example data flow performed by Data Intake and Query system (108), in accordance with the disclosed embodiments. The data flow illustrated inFIG. 3is provided for illustrative purposes only; those skilled in the art would understand that one or more of the blocks of the processes illustrated inFIG. 3may be removed or the ordering of the blocks may be changed. Furthermore, for the purposes of illustrating a clear example, one or more particular system components are described in the context of performing various operations during each of the data flow stages. For example, a forwarder is described as receiving and processing data during an input phase; an indexer is described as parsing and indexing data during parsing and indexing phases; and a search head is described as performing a search query during a search phase. However, other system arrangements and distributions of the processing blocks across system components may be used.\n\n2.5.1. Input\n\nAt block (302), a forwarder receives data from an input source, such as a data source (202) shown inFIG. 2. A forwarder initially may receive the data as a raw data stream generated by the input source. For example, a forwarder may receive a data stream from a log file generated by an application server, from a stream of network data from a network device, or from any other source of data. In one embodiment, a forwarder receives the raw data and may segment the data stream into \u201cblocks\u201d, or \u201cbuckets,\u201d possibly of a uniform data size, to facilitate subsequent processing blocks.\n\nAt block (304), a forwarder or other system component annotates each block generated from the raw data with one or more metadata fields. These metadata fields may, for example, provide information related to the data block as a whole and may apply to each event that is subsequently derived from the data in the data block. For example, the metadata fields may include separate fields specifying each of a host, a source, and a source type related to the data block. A host field may contain a value identifying a host name or IP address of a device that generated the data. A source field may contain a value identifying a source of the data, such as a pathname of a file or a protocol and port related to received network data. A source type field may contain a value specifying a particular source type label for the data. Additional metadata fields may also be included during the input phase, such as a character encoding of the data, if known, and possibly other values that provide information relevant to later processing blocks. In an embodiment, a forwarder forwards the annotated data blocks to another system component (typically an indexer) for further processing.\n\nThe SPLUNK\u00ae ENTERPRISE system allows forwarding of data from one SPLUNK\u00ae ENTERPRISE instance to another, or even to a third-party system. SPLUNK\u00ae ENTERPRISE system can employ different types of forwarders in a configuration.\n\nIn an embodiment, a forwarder may contain the essential components needed to forward data. It can gather data from a variety of inputs and forward the data to a SPLUNK\u00ae ENTERPRISE server for indexing and searching. It also can tag metadata (e.g., source, source type, host, etc.).\n\nAdditionally or optionally, in an embodiment, a forwarder has the capabilities of the aforementioned forwarder as well as additional capabilities. The forwarder can parse data before forwarding the data (e.g., associate a time stamp with a portion of data and create an event, etc.) and can route data based on criteria such as source or type of event. It can also index data locally while forwarding the data to another indexer.\n\n2.5.2. Parsing\n\nAt block (306), an indexer receives data blocks from a forwarder and parses the data to organize the data into events. In an embodiment, to organize the data into events, an indexer may determine a source type associated with each data block (e.g., by extracting a source type label from the metadata fields associated with the data block, etc.) and refer to a source type configuration corresponding to the identified source type. The source type definition may include one or more properties that indicate to the indexer to automatically determine the boundaries of events within the data. In general, these properties may include regular expression-based rules or delimiter rules where, for example, event boundaries may be indicated by predefined characters or character strings. These predefined characters may include punctuation marks or other special characters including, for example, carriage returns, tabs, spaces, line breaks, etc. If a source type for the data is unknown to the indexer, an indexer may infer a source type for the data by examining the structure of the data. Then, it can apply an inferred source type definition to the data to create the events.\n\nAt block (308), the indexer determines a timestamp for each event. Similar to the process for creating events, an indexer may again refer to a source type definition associated with the data to locate one or more properties that indicate instructions for determining a timestamp for each event. The properties may, for example, instruct an indexer to extract a time value from a portion of data in the event, to interpolate time values based on timestamps associated with temporally proximate events, to create a timestamp based on a time the event data was received or generated, to use the timestamp of a previous event, or use any other rules for determining timestamps.\n\nAt block (310), the indexer associates with each event one or more metadata fields including a field containing the timestamp (in some embodiments, a timestamp may be included in the metadata fields) determined for the event. These metadata fields may include a number of \u201cdefault fields\u201d that are associated with all events, and may also include one more custom fields as defined by a user. Similar to the metadata fields associated with the data blocks at block (304), the default metadata fields associated with each event may include a host, source, and source type field including or in addition to a field storing the timestamp.\n\nAt block (312), an indexer may optionally apply one or more transformations to data included in the events created at block (306). For example, such transformations can include removing a portion of an event (e.g., a portion used to define event boundaries, extraneous characters from the event, other extraneous text, etc.), masking a portion of an event (e.g., masking a credit card number), removing redundant portions of an event, etc. The transformations applied to event data may, for example, be specified in one or more configuration files and referenced by one or more source type definitions.\n\n2.5.3. Indexing\n\nAt blocks (314) and (316), an indexer can optionally generate a keyword index to facilitate fast keyword searching for event data. To build a keyword index, at block (314), the indexer identifies a set of keywords in each event. At block (316), the indexer includes the identified keywords in an index, which associates each stored keyword with reference pointers to events containing that keyword (or to locations within events where that keyword is located, other location identifiers, etc.). When an indexer subsequently receives a keyword-based query, the indexer can access the keyword index to quickly identify events containing the keyword.\n\nIn some embodiments, the keyword index may include entries for name-value pairs found in events, where a name-value pair can include a pair of keywords connected by a symbol, such as an equals sign or colon. This way, events containing these name-value pairs can be quickly located. In some embodiments, fields can automatically be generated for some or all of the name-value pairs at the time of indexing. For example, if the string \u201cdest=10.0.1.2\u201d is found in an event, a field named \u201cdest\u201d may be created for the event, and assigned a value of \u201c10.0.1.2\u201d.\n\nAt block (318), the indexer stores the events with an associated timestamp in a data store (208). Timestamps enable a user to search for events based on a time range. In one embodiment, the stored events are organized into \u201cbuckets,\u201d where each bucket stores events associated with a specific time range based on the timestamps associated with each event. This may not only improve time-based searching, but also allows for events with recent timestamps, which may have a higher likelihood of being accessed, to be stored in a faster memory to facilitate faster retrieval. For example, buckets containing the most recent events can be stored in flash memory rather than on a hard disk. In the example, the flash memory and the hard disk may be remote storage. Other configurations may be used without departing from the scope of the invention.\n\nEach indexer (206) may be responsible for storing and searching a subset of the events contained in a corresponding data store (208). By distributing events among the indexers and data stores, the indexers can analyze events for a query in parallel. For example, using map-reduce techniques, each indexer returns partial responses for a subset of events to a search head that combines the results to produce an answer for the query. By storing events in buckets for specific time ranges, an indexer may further optimize data retrieval process by searching buckets corresponding to time ranges that are relevant to a query.\n\nMoreover, events and buckets can also be replicated across different indexers and data stores to facilitate high availability and disaster recovery as described in U.S. patent application Ser. No. 14/266,812, entitled \u201cSITE-BASED SEARCH AFFINITY\u201d, filed on 30 Apr. 2014, and in U.S. patent application Ser. No. 14/266,817, entitled \u201cMULTI-SITE CLUSTERING\u201d, also filed on 30 Apr. 2014, each of which is hereby incorporated by reference in its entirety for all purposes.\n\n2.6. Query Processing\n\nFIG. 4is a flow diagram that illustrates an exemplary process that a search head and one or more indexers may perform during a search query. At block (402), a search head receives a search query from a client. At block (404), the search head analyzes the search query to determine what portion(s) of the query can be delegated to indexers and what portions of the query can be executed locally by the search head. At block (406), the search head distributes the determined portions of the query to the appropriate indexers. In an embodiment, a search head cluster may take the place of an independent search head where each search head in the search head cluster coordinates with peer search heads in the search head cluster to schedule jobs, replicate search results, update configurations, fulfill search requests, etc. In an embodiment, the search head (or each search head) communicates with a master node (also known as a cluster master, not shown in the Figure) that provides the search head with a list of indexers to which the search head can distribute the determined portions of the query. The master node maintains a list of active indexers and can also designate which indexers may have responsibility for responding to queries over certain sets of events. A search head may communicate with the master node before the search head distributes queries to indexers to discover the addresses of active indexers.\n\nAt block (408), the indexers to which the query was distributed, search data stores associated with them for events that are responsive to the query. To determine which events are responsive to the query, the indexer searches for events that match the criteria specified in the query. These criteria can include matching keywords or specific values for certain fields. The searching operations at block (408) may use the late-binding schema to extract values for specified fields from events at the time the query is processed. In an embodiment, one or more rules for extracting field values may be specified as part of a source type definition. The indexers may then either send the relevant events back to the search head, or use the events to determine a partial result, and send the partial result back to the search head.\n\nAt block (410), the search head combines the partial results and/or events received from the indexers to produce a final result for the query. This final result may comprise different types of data depending on what the query requested. For example, the results can include a listing of matching events returned by the query, or some type of visualization of the data from the returned events. In another example, the final result can include one or more calculated values derived from the matching events.\n\nThe results generated by the system (108) can be returned to a client using different techniques. For example, one technique streams results or relevant events back to a client in real-time as they are identified. Another technique waits to report the results to the client until a complete set of results (which may include a set of relevant events or a result based on relevant events) is ready to return to the client. Yet another technique streams interim results or relevant events back to the client in real-time until a complete set of results is ready, and then returns the complete set of results to the client. In another technique, certain results are stored as \u201csearch jobs\u201d and the client may retrieve the results by referring the search jobs.\n\nThe search head can also perform various operations to make the search more efficient. For example, before the search head begins execution of a query, the search head can determine a time range for the query and a set of common keywords that all matching events include. The search head may then use these parameters to query the indexers to obtain a superset of the eventual results. Then, during a filtering stage, the search head can perform field-extraction operations on the superset to produce a reduced set of search results. This speeds up queries that are performed on a periodic basis.\n\n2.7. Field Extraction\n\nThe search head (210) allows users to search and visualize event data extracted from raw machine data received from homogenous data sources. It also allows users to search and visualize event data extracted from raw machine data received from heterogeneous data sources. The search head (210) includes various mechanisms, which may additionally reside in an indexer (206), for processing a query. Splunk Processing Language (SPL), used in conjunction with the SPLUNK\u00ae ENTERPRISE system, can be utilized to make a query. SPL is a pipelined search language in which a set of inputs is operated on by a first command in a command line, and then a subsequent command following the pipe symbol \u201cI\u201d operates on the results produced by the first command, and so on for additional commands. Other query languages, such as the Structured Query Language (SQL), can be used to create a query.\n\nIn response to receiving the search query, search head (210) uses extraction rules to extract values for the fields associated with a field or fields in the event data being searched. The search head (210) obtains extraction rules that specify how to extract a value for certain fields from an event. Extraction rules can comprise regex rules that specify how to extract values for the relevant fields. In addition to specifying how to extract field values, the extraction rules may also include instructions for deriving a field value by performing a function on a character string or value retrieved by the extraction rule. For example, a transformation rule may truncate a character string, or convert the character string into a different data format. In some cases, the query itself can specify one or more extraction rules.\n\nThe search head (210) can apply the extraction rules to event data that it receives from indexers (206). Indexers (206) may apply the extraction rules to events in an associated data store (208). Extraction rules can be applied to all the events in a data store, or to a subset of the events that have been filtered based on some criteria (e.g., event time stamp values, etc.). Extraction rules can be used to extract one or more values for a field from events by parsing the event data and examining the event data for one or more patterns of characters, numbers, delimiters, etc., that indicate where the field begins and, optionally, ends.\n\nFIG. 5illustrates an example of raw machine data received from disparate data sources. In this example, a user submits an order for merchandise using a vendor's shopping application program (501) running on the user's system. In this example, the order was not delivered to the vendor's server due to a resource exception at the destination server that is detected by the middleware code (502). The user then sends a message to the customer support (503) to complain about the order failing to complete. The three systems (501), (502), and (503) are disparate systems that do not have a common logging format. The order application (501) sends log data (504) to the SPLUNK\u00ae ENTERPRISE system in one format, the middleware code (502) sends error log data (505) in a second format, and the support server (503) sends log data (506) in a third format.\n\nUsing the log data received at one or more indexers (206) from the three systems the vendor can uniquely obtain an insight into user activity, user experience, and system behavior. The search head (210) allows the vendor's administrator to search the log data from the three systems that one or more indexers (206) are responsible for searching, thereby obtaining correlated information, such as the order number and corresponding customer ID number of the person placing the order. The system also allows the administrator to see a visualization of related events via a user interface. The administrator can query the search head (210) for customer ID field value matches across the log data from the three systems that are stored at the one or more indexers (206). The customer ID field value exists in the data gathered from the three systems, but the customer ID field value may be located in different areas of the data given differences in the architecture of the systems\u2014there is a semantic relationship between the customer ID field values generated by the three systems. The search head (210) requests event data from the one or more indexers (206) to gather relevant event data from the three systems. It then applies extraction rules to the event data in order to extract field values that it can correlate. The search head may apply a different extraction rule to each set of events from each system when the event data format differs among systems. In this example, the user interface can display to the administrator the event data corresponding to the common customer ID field values (507), (508), and (509), thereby providing the administrator with insight into a customer's experience.\n\nNote that query results can be returned to a client, a search head, or any other system component for further processing. In general, query results may include a set of one or more events, a set of one or more values obtained from the events, a subset of the values, statistics calculated based on the values, a report containing the values, or a visualization, such as a graph or chart, generated from the values.\n\n2.8. Cloud-Based System Overview\n\nThe example data intake and query system (108) described in reference toFIG. 2comprises several system components, including one or more forwarders, indexers, and search heads. In some environments, a user of a data intake and query system (108) may install and configure, on computing devices owned and operated by the user, one or more software applications that implement some or all of these system components. For example, a user may install a software application on server computers owned by the user and configure each server to operate as one or more of a forwarder, an indexer, a search head, etc. This arrangement generally may be referred to as an \u201con-premises\u201d solution. That is, the system (108) is installed and operates on computing devices directly controlled by the user of the system. Some users may prefer an on-premises solution because it may provide a greater level of control over the configuration of certain aspects of the system (e.g., security, privacy, standards, controls, etc.). However, other users may instead prefer an arrangement in which the user is not directly responsible for providing and managing the computing devices upon which various components of system (108) operate.\n\nIn one embodiment, to provide an alternative to an entirely on-premises environment for system (108), one or more of the components of a data intake and query system instead may be provided as a cloud-based service. In this context, a cloud-based service refers to a service hosted by one more computing resources that are accessible to end users over a network, for example, by using a web browser or other application on a client device to interface with the remote computing resources. For example, a service provider may provide a cloud-based data intake and query system by managing computing resources configured to implement various aspects of the system (e.g., forwarders, indexers, search heads, etc.) and by providing access to the system to end users via a network. Typically, a user may pay a subscription or other fee to use such a service. Each subscribing user of the cloud-based service may be provided with an account that enables the user to configure a customized cloud-based system based on the user's preferences.\n\nFIG. 6illustrates a block diagram of an example cloud-based data intake and query system. Similar to the system ofFIG. 2, the networked computer system (600) includes input data sources (202) and forwarders (204). These input data sources and forwarders may be in a subscriber's private computing environment. Alternatively, they might be directly managed by the service provider as part of the cloud service. In the example system (600), one or more forwarders (204) and client devices (602) are coupled to a cloud-based data intake and query system (606) via one or more networks (604). Network (604) broadly represents one or more LANs, WANs, cellular networks, intranet, etc., using any of wired, wireless, terrestrial microwave, satellite links, etc., and may include the public Internet, and is used by client devices (602) and forwarders (204) to access the system (606). Similar to the system of (108), each of the forwarders (204) may be configured to receive data from an input source and to forward the data to other components of the system (606) for further processing.\n\nIn an embodiment, a cloud-based data intake and query system (606) may comprise a plurality of system instances (608). In general, each system instance (608) may include one or more computing resources managed by a provider of the cloud-based system (606) made available to a particular subscriber. The computing resources comprising a system instance (608) may, for example, include one or more servers or other devices configured to implement one or more forwarders, indexers, search heads, and other components of a data intake and query system, similar to system (108). As indicated above, a subscriber may use a web browser or other application of a client device (602) to access a web portal or other interface that enables the subscriber to configure an instance (608).\n\nProviding a data intake and query system as described in reference to system (108) as a cloud-based service presents a number of challenges. Each of the components of a system (108) (e.g., forwarders, indexers and search heads) may at times refer to various configuration files stored locally at each component. These configuration files typically may involve some level of user configuration to accommodate particular types of data a user desires to analyze and to account for other user preferences. However, in a cloud-based service context, users typically may not have direct access to the underlying computing resources implementing the various system components (e.g., the computing resources comprising each system instance (608)) and may desire to make such configurations indirectly, for example, using one or more web-based interfaces. Thus, the techniques and systems described herein for providing user interfaces that enable a user to configure source type definitions are applicable to both on-premises and cloud-based service contexts, or some combination thereof (e.g., a hybrid system where both an on-premises environment such as SPLUNK\u00ae ENTERPRISE and a cloud-based environment such as SPLUNK CLOUD\u2122 are centrally visible).\n\n2.9. Searching Externally Archived Data\n\nFIG. 7shows a block diagram of an example of a data intake and query system (108) that provides transparent search facilities for data systems that are external to the data intake and query system. Such facilities are available in the HUNK\u00ae system provided by Splunk Inc. of San Francisco, Calif. HUNK\u00ae represents an analytics platform that enables business and IT teams to rapidly explore, analyze, and visualize data in Hadoop and NoSQL data stores.\n\nThe search head (210) of the data intake and query system receives search requests from one or more client devices (704) over network connections (720). As discussed above, the data intake and query system (108) may reside in an enterprise location, in the cloud, etc.FIG. 7illustrates that multiple client devices (704a), (704b), . . . , (704n) may communicate with the data intake and query system (108). The client devices (704) may communicate with the data intake and query system using a variety of connections. For example, one client device inFIG. 7is illustrated as communicating over an Internet (Web) protocol, another client device is illustrated as communicating via a command line interface, and another client device is illustrated as communicating via a system developer kit (SDK).\n\nThe search head (210) analyzes the received search request to identify request parameters. If a search request received from one of the client devices (704) references an index maintained by the data intake and query system, then the search head (210) connects to one or more indexers (206) of the data intake and query system for the index referenced in the request parameters. That is, if the request parameters of the search request reference an index, then the search head accesses the data in the index via the indexer. The data intake and query system (108) may include one or more indexers (206), depending on system access resources and requirements. As described further below, the indexers (206) retrieve data from their respective local data stores (208) as specified in the search request. The indexers and their respective data stores can comprise one or more storage devices and typically reside on the same system, though they may be connected via a local network connection.\n\nIf the request parameters of the received search request reference an external data collection, which is not accessible to the indexers (206) or under the management of the data intake and query system, then the search head (210) can access the external data collection through an External Result Provider (ERP) process (710). An external data collection may be referred to as a \u201cvirtual index\u201d (plural, \u201cvirtual indices\u201d). An ERP process provides an interface through which the search head (210) may access virtual indices.\n\nThus, a search reference to an index of the system relates to a locally stored and managed data collection. In contrast, a search reference to a virtual index relates to an externally stored and managed data collection, which the search head may access through one or more ERP processes (710), (712).FIG. 7shows two ERP processes (710), (712) that connect to respective remote (external) virtual indices, which are indicated as a Hadoop or another system (714) (e.g., Amazon S3, Amazon EMR, other Hadoop Compatible File Systems (HCFS), etc.) and a relational database management system (RDBMS) (718). Other virtual indices may include other file organizations and protocols, such as Structured Query Language (SQL) and the like. The ellipses between the ERP processes (710), (712) indicate optional additional ERP processes of the data intake and query system (108). An ERP process may be a computer process that is initiated or spawned by the search head (210) and is executed by the search data intake and query system (108). Alternatively or additionally, an ERP process may be a process spawned by the search head (210) on the same or different host system as the search head (210) resides.\n\nThe search head (210) may spawn a single ERP process in response to multiple virtual indices referenced in a search request, or the search head may spawn different ERP processes for different virtual indices. Generally, virtual indices that share common data configurations or protocols may share ERP processes. For example, all search query references to a Hadoop file system may be processed by the same ERP process, if the ERP process is suitably configured. Likewise, all search query references to an SQL database may be processed by the same ERP process. In addition, the search head may provide a common ERP process for common external data source types (e.g., a common vendor may utilize a common ERP process, even if the vendor includes different data storage system types, such as Hadoop and SQL). Common indexing schemes also may be handled by common ERP processes, such as flat text files or Weblog files.\n\nThe search head (210) determines the number of ERP processes to be initiated via the use of configuration parameters that are included in a search request message. Generally, there is a one-to-many relationship between an external results provider \u201cfamily\u201d and ERP processes. There is also a one-to-many relationship between an ERP process and corresponding virtual indices that are referred to in a search request. For example, using RDBMS, assume two independent instances of such a system by one vendor, such as one RDBMS for production and another RDBMS used for development. In such a situation, it is likely preferable (but optional) to use two ERP processes to maintain the independent operation as between production and development data. Both of the ERPs, however, will belong to the same family, because the two RDBMS system types are from the same vendor.\n\nThe ERP processes (710), (712) receive a search request from the search head (210). The search head may optimize the received search request for execution at the respective external virtual index. Alternatively, the ERP process may receive a search request as a result of analysis performed by the search head or by a different system process. The ERP processes (710), (712) can communicate with the search head (210) via conventional input/output routines (e.g., standard in/standard out, etc.). In this way, the ERP process receives the search request from a client device such that the search request may be efficiently executed at the corresponding external virtual index.\n\nThe ERP processes (710), (712) may be implemented as a process of the data intake and query system. Each ERP process may be provided by the data intake and query system, or may be provided by process or application providers who are independent of the data intake and query system. Each respective ERP process may include an interface application installed at a computer of the external result provider that ensures proper communication between the search support system and the external result provider. The ERP processes (710), (712) generate appropriate search requests in the protocol and syntax of the respective virtual indices (714), (718), each of which corresponds to the search request received by the search head (210). Upon receiving search results from their corresponding virtual indices, the respective ERP process passes the result to the search head (210), which may return or display the results or a processed set of results based on the returned results to the respective client device.\n\nClient devices (704) may communicate with the data intake and query system (108) through a network interface (720), e.g., one or more LANs, WANs, cellular networks, and/or intranet using any of wired, wireless, terrestrial microwave, satellite links, etc., and may include the public Internet.\n\nThe analytics platform utilizing the External Result Provider process described in more detail in U.S. Pat. No. 8,738,629, entitled \u201cEXTERNAL RESULT PROVIDED PROCESS FOR RETRIEVING DATA STORED USING A DIFFERENT CONFIGURATION OR PROTOCOL\u201d, issued on 27 May 2014, U.S. Pat. No. 8,738,587, entitled \u201cPROCESSING A SYSTEM SEARCH REQUEST BY RETRIEVING RESULTS FROM BOTH A NATIVE INDEX AND A VIRTUAL INDEX\u201d, issued on 25 Jul. 2013, U.S. patent application Ser. No. 14/266,832, entitled \u201cPROCESSING A SYSTEM SEARCH REQUEST ACROSS DISPARATE DATA COLLECTION SYSTEMS\u201d, filed on 1 May 2014, and U.S. patent application Ser. No. 14/449,144, entitled \u201cPROCESSING A SYSTEM SEARCH REQUEST INCLUDING EXTERNAL DATA SOURCES\u201d, filed on 31 Jul. 2014, each of which is hereby incorporated by reference in its entirety for all purposes.\n\n2.9.1. ERP Process Features\n\nThe ERP processes described above may include two operation modes: a streaming mode and a reporting mode. The ERP processes can operate in streaming mode only, in reporting mode only, or in both modes simultaneously. Operating in both modes simultaneously is referred to as mixed mode operation. In a mixed mode operation, the ERP at some point can stop providing the search head with streaming results and only provide reporting results thereafter, or the search head at some point may start ignoring streaming results it has been using and only use reporting results thereafter.\n\nThe streaming mode returns search results in real time, with minimal processing, in response to the search request. The reporting mode provides results of a search request with processing of the search results prior to providing them to the requesting search head, which in turn provides results to the requesting client device. ERP operation with such multiple modes provides greater performance flexibility with regard to report time, search latency, and resource utilization.\n\nIn a mixed mode operation, both streaming mode and reporting mode are operating simultaneously. The streaming mode results (e.g., the raw data obtained from the external data source) are provided to the search head, which can then process the results data (e.g., break the raw data into events, timestamp it, filter it, etc.) and integrate the results data with the results data from other external data sources, and/or from data stores of the search head. The search head performs such processing and can immediately start returning interim (streaming mode) results to the user at the requesting client device; simultaneously, the search head is waiting for the ERP process to process the data it is retrieving from the external data source as a result of the concurrently executing reporting mode.\n\nIn some instances, the ERP process initially operates in a mixed mode, such that the streaming mode operates to enable the ERP quickly to return interim results (e.g., some of the raw or unprocessed data necessary to respond to a search request) to the search head, enabling the search head to process the interim results and begin providing to the client or search requester interim results that are responsive to the query. Meanwhile, in this mixed mode, the ERP also operates concurrently in reporting mode, processing portions of raw data in a manner responsive to the search query. Upon determining that it has results from the reporting mode available to return to the search head, the ERP may halt processing in the mixed mode at that time (or some later time) by stopping the return of data in streaming mode to the search head and switching to reporting mode only. The ERP at this point starts sending interim results in reporting mode to the search head, which in turn may then present this processed data responsive to the search request to the client or search requester. Typically, the search head switches from using results from the ERP's streaming mode of operation to results from the ERP's reporting mode of operation when the higher bandwidth results from the reporting mode outstrip the amount of data processed by the search head in the]streaming mode of ERP operation.\n\nA reporting mode may have a higher bandwidth because the ERP does not have to spend time transferring data to the search head for processing all the raw data. In addition, the ERP may optionally direct another processor to do the processing.\n\nThe streaming mode of operation does not need to be stopped to gain the higher bandwidth benefits of a reporting mode; the search head could simply stop using the streaming mode results\u2014and start using the reporting mode results\u2014when the bandwidth of the reporting mode has caught up with or exceeded the amount of bandwidth provided by the streaming mode. Thus, a variety of triggers and ways to accomplish a search head's switch from using streaming mode results to using reporting mode results may be appreciated by one skilled in the art.\n\nThe reporting mode can involve the ERP process (or an external system) performing event breaking, time stamping, filtering of events to match the search query request, and calculating statistics on the results. The user can request particular types of data, such as if the search query itself involves types of events, or the search request may ask for statistics on data, such as on events that meet the search request. In either case, the search head understands the query language used in the received query request, which may be a proprietary language. One exemplary query language is Splunk Processing Language (SPL) developed by the assignee of the application, Splunk Inc. The search head typically understands how to use that language to obtain data from the indexers, which store data in a format used by the SPLUNK\u00ae Enterprise system.\n\nThe ERP processes support the search head, as the search head is not ordinarily configured to understand the format in which data is stored in external data sources such as Hadoop or SQL data systems. Rather, the ERP process performs that translation from the query submitted in the search support system's native format (e.g., SPL if SPLUNK\u00ae ENTERPRISE is used as the search support system) to a search query request format that will be accepted by the corresponding external data system. The external data system typically stores data in a different format from that of the search support system's native index format, and it utilizes a different query language (e.g., SQL or MapReduce, rather than SPL or the like).\n\nAs noted, the ERP process can operate in the streaming mode alone. After the ERP process has performed the translation of the query request and received raw results from the streaming mode, the search head can integrate the returned data with any data obtained from local data sources (e.g., native to the search support system), other external data sources, and other ERP processes (if such operations were required to satisfy the terms of the search query). An advantage of mixed mode operation is that, in addition to streaming mode, the ERP process is also executing concurrently in reporting mode. Thus, the ERP process (rather than the search head) is processing query results (e.g., performing event breaking, timestamping, filtering, possibly calculating statistics if required to be responsive to the search query request, etc.). It should be apparent to those skilled in the art that additional time is needed for the ERP process to perform the processing in such a configuration. Therefore, the streaming mode will allow the search head to start returning interim results to the user at the client device before the ERP process can complete sufficient processing to start returning any search results. The switchover between streaming and reporting mode happens when the ERP process determines that the switchover is appropriate, such as when the ERP process determines it can begin returning meaningful results from its reporting mode.\n\nThe operation described above illustrates the source of operational latency: streaming mode has low latency (immediate results) and usually has relatively low bandwidth (fewer results can be returned per unit of time). In contrast, the concurrently running reporting mode has relatively high latency (it has to perform a lot more processing before returning any results) and usually has relatively high bandwidth (more results can be processed per unit of time). For example, when the ERP process does begin returning report results, it returns more processed results than in the streaming mode, because, e.g., statistics only need to be calculated to be responsive to the search request. That is, the ERP process doesn't have to take time to first return raw data to the search head. As noted, the ERP process could be configured to operate in streaming mode alone and return just the raw data for the search head to process in a way that is responsive to the search request. Alternatively, the ERP process can be configured to operate in the reporting mode only. Also, the ERP process can be configured to operate in streaming mode and reporting mode concurrently, as described, with the ERP process stopping the transmission of streaming results to the search head when the concurrently running reporting mode has caught up and started providing results. The reporting mode does not require the processing of all raw data that is responsive to the search query request before the ERP process starts returning results; rather, the reporting mode usually performs processing of chunks of events and returns the processing results to the search head for each chunk.\n\nFor example, an ERP process can be configured to merely return the contents of a search result file verbatim, with little or no processing of results. That way, the search head performs all processing (such as parsing byte streams into events, filtering, etc.). The ERP process can be configured to perform additional intelligence, such as analyzing the search request and handling all the computation that a native search indexer process would otherwise perform. In this way, the configured ERP process provides greater flexibility in features while operating according to desired preferences, such as response latency and resource requirements.\n\n3.0. Geographic Positioning Subsystem\n\nFIG. 8Ashows a geographic positioning subsystem (800) in accordance with one or more embodiments of the invention. As shown inFIG. 8A, the geographic positioning subsystem (800) includes a mobile device (802) and a locale (804). In one or more embodiments, the mobile device (802) is any type of computing system, such as a client device (102). In one or more embodiments, the mobile device (802) may be a laptop computer, smart phone, personal digital assistant, tablet computer, gaming console, or any other type of electronic device or devices that includes at least the minimum processing power, memory, and input and output device(s) to perform one or more embodiments. For example, the mobile device (802) may include one or more hardware processor(s), associated memory (e.g., random access memory (RAM), cache memory, flash memory, etc.), one or more storage target device(s) (e.g., a hard disk, an optical drive such as a compact disk (CD) drive or digital versatile disk (DVD) drive, a flash memory stick, etc.), and numerous other elements and functionalities. The hardware processor(s) may be an integrated circuit for processing instructions. For example, the hardware processor(s) may be one or more cores, or micro-cores of a processor.\n\nIn one or more embodiments, the locale (804) includes zones (806), network devices (808), registers (810), external data sources (812), and a geographic position analyzer (814). In one or more embodiments, the locale (804) may represent a physical (e.g., brick-and-mortar) retail store. In one or more embodiments, the locale (804) is divided into zones (806). For example, a zone (806) may refer to a specific region of the locale (804), such as an entrance zone, shopping zone, zones of the shopping zone, lounge zone, order pickup zone, register (e.g., checkout) zone, external zone, customer service zone, food service zone, etc.\n\nIn one or more embodiments, the network devices (808) may be host devices (106) (e.g., a collection of host devices (106)) configured to implement a network-based service, such as provide a connection to a network (104). In one or more embodiments, a network device (808) may be a wireless access point that is wirelessly communicatively connected to the mobile device (802) and is in a communication path from the mobile device (802) to a wireless network (not shown). In one or more embodiments, the wireless access point may be directly connected via a direct wireless connection to a network interface card on the mobile device (802). In addition, wireless access points may be directly connected to the wireless network or connected to the wireless network via a controller. By way of an example, the wireless access point may communicate wirelessly with mobile devices (802) using Wi-Fi, Bluetooth or related standards.\n\nIn one or more embodiments, an event log (820) is associated with each network device (808). In one or more embodiments, the event log (820) includes portions of raw machine data associated with a timestamp. In one or more embodiments, the event log (820) stores a portion of raw machine data associated with a timestamp each time a mobile device (802) interacts (e.g., communicates) with the network device (808). The event log (820) for a network device (808) is described in detail inFIG. 8B.\n\nIn one or more embodiments, a register (810) includes a point-of-sale (POS) device (822). In one or more embodiments, a register (810) is a location of a locale at which a customer may complete a purchase of at least one product. For example, the POS device may total an amount of a sales transaction and the customer may provide financial account information or money to pay for the sales transaction. The register may or may not include a cashier and a waiting space for a waiting line for customers (e.g., customers waiting to complete a sales transaction).\n\nIn one or more embodiments, a POS device (822) includes functionality to process purchases, scan product codes to identify purchased products, and perform other functions related to the sale of products. For example, a POS device (822) may include a card reader (e.g., credit/debit card reader), a bar code reader, a receipt printer, an inventory scanner (e.g., RFID, Bar Code, Quick Response (QR) codes/matrix barcodes, etc.), a pin pad, computer system(s), and other devices. In one or more embodiments, the POS device (822) may include, or may itself be a part of, a cash register, a credit card scanner, or any other type of POS device.\n\nIn one or more embodiments, external data sources (812) include sales logs (824), mobile applications (826), sensors (828), an inventory system (830), etc. In one or more embodiments, a sales log (824) includes sales transactions obtained from a POS device (822). In one or more embodiments, the external data sources (812) may be accessible via a network (e.g., a wireless network specific to the locale (804)) that is separate from the network devices (808). In one or more embodiments, the external data sources (812) may be accessible via an application programming interface (API).\n\nIn one or more embodiments, a mobile application (826) includes user data corresponding to a user of the mobile device (802). In one or more embodiments, the user data includes previous sales transactions of the user (e.g., sales transactions occurring at the locale (804)), various other customer relationship management (CRM) data (e.g., a customer profile and demographics) corresponding to the user, etc. For example, the previous sales transactions of the user may include data on promotions redeemed by the user.\n\nIn one or more embodiments, the user data from the mobile application (826) may be combined with user data obtained from a website associated with the locale (804). For example, the website may be an online retail website associated with the locale (804) that includes user data related to online sales transactions of the user.\n\nIn one or more embodiments, sensors (828) include touch sensors, proximity sensors, optical sensors, motion sensors, auditory sensors, door chime sensors, etc. For example, a door chime sensor may generate sensor data that may be used to measure the size of walk-by traffic entering the locale (804). In one or more embodiments, a sensor (828) may generate sensor data that may be used in determining a geographic position of a mobile device (802).\n\nIn one or more embodiments, an inventory system (830) manages inventory items (e.g., products) at the locale (804). For example, the inventory system (830) may track the quantities of each inventory item at the locale (804). As another example, the inventory system (830) may track the expiration date of an inventory item at the locale (804). For example, a batch of inventory items may be associated with an expiration date. The inventory system (830) may also assist in ordering new inventory items, restocking existing inventory items, tracking customers and suppliers, selling inventory items, and performing other functions related to inventory. In one or more embodiments, the inventory system (830) includes functionality to update and receive updates when inventory items are sold via a POS device (822) at the locale (804).\n\n3.1. Geographic Positioning Analyzer\n\nIn one or more embodiments, the geographic position analyzer (814) may be implemented in hardware (e.g., circuitry), software, or any combination thereof. In one or more embodiments, the geographic position analyzer (814) is a host application (114) executing on a host device (106). In one or more embodiments, the geographic position analyzer (108) is implemented as a component of the data intake and query system (108). In one or more embodiments, the geographic position analyzer (814) includes functionality to access external data sources (812) (e.g., via a wireless network of the locale (804))). In one or more embodiments, the geographic position analyzer (814) includes functionality to access network devices (808) (e.g., via network (104)).\n\nTurning toFIG. 8B, in one or more embodiments, the event log (820) corresponds to a specific network device (808). In other words, each network device (808) may include a unique event log for the network device. In some embodiments, the event log is shared by network devices that appends log entries to the end of the event log with an identifier of the network device.\n\nIn one or more embodiments, the event log (820) includes a series of event log entries (832), each including a mobile device ID (838), a timestamp (840), and an interaction type (842). In one or more embodiments, each event log entry (832) describes an interaction between a mobile device (802) and a network device (808) (e.g., the network device (808) corresponding to the event log (820)). For example, the interaction may be the mobile device requesting to access the network from the network device, the mobile device receiving data from the network via the network device, the connection between the mobile device and the network device being terminated, a device discovery communication between the mobile device and the network device, and other interactions. The mobile device ID (838) may be any identifier that uniquely identifies the mobile device (802). For example, the mobile device ID (838) may be a media access control (MAC) address of the mobile device (802). The timestamp (840) records a time of the interaction between the mobile device and the network device. In one or more embodiments, the timestamp records a single point in time of initiation or completion of the interaction. In one or more embodiments, the interaction type (842) stores a type of communication between the network device (808) and the mobile device (802). In one or more embodiments, the interaction type (842) may be: a request to initiate a connection, a request to receive data, a request to send data, a data transmission, a request to terminate a connection, and/or any other data request or data transmission as defined by a communication protocol (e.g., IEEE 802.11).\n\nIn one or more embodiments, the sales log (824) includes a series of sales transactions (844), each including a POS device ID (846), a transaction amount (848), a timestamp (840), products (870), and promotions (880). In one or more embodiments, the POS device ID (846) is any identifier that uniquely identifies a POS device (822). The transaction amount (848) lists the monetary amount exchanged during the sales transaction. The timestamp (840) is the time of the sales transaction (e.g., time of completion of the sales transaction). The products (870) are a list of products exchanged during the sales transaction. The promotions (880) are any marketing promotions applied to the sales transaction. The marketing promotions may include coupons, discounts for purchases of multiple units, customer loyalty discounts and other sales promotions that are performed to increase sales of one or more products.\n\nTurning toFIG. 8C, in one or more embodiments, each product (870) includes a product ID (872), a quantity (874), a unit price (876), and an extended price (878). In one or more embodiments, the product ID (872) may be a stock keeping unit (SKU) identifier or other product code. The quantity (874) is the number of units sold. The unit price (876) is the price per unit sold. The extended price is the total for the number of units. In one or more embodiments, the promotion (880) includes a promotion ID (882), an override flag (884), a failure flag (886), and a discount (888). The promotion ID (882) is a unique identifier of the promotion. The product ID (872) uniquely identifies the product or products in the promotion. In one or more embodiments, the override flag (884) indicates whether a manager override was required to process the corresponding promotion (880). For example, the POS device (822) (e.g., the POS device (822) corresponding to the POS device ID (846) of the sales transaction (844)) may have initially rejected the promotion (880), and a manager override was eventually required to redeem the promotion (880). In one or more embodiments, the failure flag (886) indicates whether the corresponding promotion (880) was unable to be processed. For example, the POS device (822) may have been unable to process the promotion (880) due to a software or hardware error in the POS device (822). In one or more embodiments, the discount (888) indicates the amount saved by redeeming the promotion (880).\n\nTurning toFIG. 8D, in one or more embodiments, the geographic position analyzer (814) includes cluster data (860). In one or more embodiments, the cluster data (860) includes a series of device-cluster assignments (862) for different mobile devices (802). In one or more embodiments, each device-cluster assignment (862) includes a mobile device ID (838) (e.g., a MAC address of the mobile device (802)), a user (864) (e.g., a user of the mobile device (802)), a cluster (866), and a membership score (868). In one or more embodiments, the user (864) of the mobile device (802) may be identified using a mobile application (826) that has access to information about the user (864). In one or more embodiments, the mobile device ID (838) of the mobile device (802) may be identified using the mobile application (826). In one or more embodiments, the cluster (866) may be assigned based on techniques for dividing a collection of mobile devices (802) into groups, called clusters, based on characteristics corresponding to the behavior of the mobile devices (802). That is, the mobile devices (802) assigned to a first cluster (866) are more similar to each other (e.g., relative to a value of the characteristic) than to mobile devices (802) assigned to other clusters (866). In one or more embodiments, the membership score (868) is a measure of the similarity of a specific mobile device (802) (e.g., the mobile device (802) corresponding to the mobile device ID (838)) relative to the average value of the characteristic in the cluster (866). In one or more embodiments, the membership score (868) of a mobile device (802) in a cluster (866) may be a percentage of the average value of the characteristic for the cluster (866). In one or more embodiments, grouping the mobile devices (802) into clusters (866) may be based on multiple characteristics.\n\nIn one or more embodiments, a fuzzy clustering technique may be used, where each mobile device (802) is a member of each cluster (866) to varying degrees, as indicated by the membership score (868) of the mobile device (802) for each cluster (866) (e.g., the membership score (868) for a mobile device (802) relative to a specific cluster (866) may be very low, even zero).\n\nIn one or more embodiments, the geographic position analyzer (814) includes functionality to determine a geographic position of a mobile device (802). In one or more embodiments, the geographic position analyzer (814) includes functionality to generate various performance metrics (e.g., sales metrics, operating metrics) for the locale (804).\n\nWhileFIG. 1,FIG. 2,FIG. 6,FIG. 7,FIG. 8A,FIG. 8B,FIG. 8C, andFIG. 8Dshow configurations of components, other configurations may be used without departing from the scope of the invention. For example, various components may be combined to create a single component. As another example, the functionality performed by a single component may be performed by two or more components.\n\n3.2. Geographic Positioning Methods\n\nFIG. 9Ashows a flowchart in accordance with one or more embodiments of the invention. In one or more embodiments, the process described in reference toFIG. 9Amay be practiced using one or more components described in reference toFIG. 1,FIG. 2,FIG. 6,FIG. 7,FIG. 8A,FIG. 8B,FIG. 8C, andFIG. 8D(e.g., the geographic positioning analyzer (814) described in reference toFIG. 8AandFIG. 8Dand the network device (808) described in reference toFIG. 8AandFIG. 8B). In one or more embodiments of the invention, one or more of the blocks shown inFIG. 9Amay be omitted, repeated, and/or performed in parallel, or in a different order than the order shown inFIG. 9A. Accordingly, the scope of the invention should not be considered limited to the specific arrangement of blocks shown inFIG. 9A.\n\nInitially, in block900, events in a field-searchable data store are accessed. In one or more embodiments, the events include raw machine data associated with a timestamp, representing interactions between a mobile device and one or more network devices at a locale. In one or more embodiments, the network device may be a wireless access point that is wirelessly communicatively connected to the mobile device and is in a communication path from the mobile device to a network. The wireless access point may communicate wirelessly with the mobile device using Wi-Fi, Bluetooth or related standards. Events may be accessed using the data intake and query system described above. For example, a query may be sent to the search head of the data intake and query system for events for a particular mobile device using the mobile device identifier. In another embodiment, the initial query may be sent for each unique mobile device identifier, and a subsequent query may be sent for at least one of the mobile devices returned. The data intake and query system processes the queries as described above. In response to the query or subsequent query the data intake and query system returns raw machine data, each corresponding to log entries in the event log and each associated with a timestamp. The log entries may each be associated with a network device identifier of the network device when returned from the data intake and query system. For each log entry, the entire or only a portion of the log entry may be returned. Further, the data intake and query system may perform initial aggregation, such as determining the duration of time that the user is logged on to the network device based on the initial access request and the termination request.\n\nIn one or more embodiments, the log entries are not processed until after the request is sent for the events. Thus, the log entries are processed on demand and remain as raw machine data until after the real-time analysis request is sent.\n\nIn block902, one or more geographic positions of the mobile device are determined, based on the interactions. In one or more embodiments, each geographic position may be a qualitative position of the mobile device, such as within a specific zone (e.g., a checkout zone, or an entrance zone). For example, an interaction between the mobile device and a single network device may be sufficient to determine a qualitative position of the mobile device within a zone of the locale. In one or more embodiments, the geographic position may be a quantitative position of the mobile device, such as numerical coordinates relative to a coordinate system (e.g., a coordinate system relative to the locale, or an absolute coordinate system). In one or more embodiments, an interaction between the mobile device and multiple network devices may be sufficient to determine a precise, quantitative position of the mobile device. In one or more embodiments, a triangulation process may be used to determine a quantitative position of the mobile device (e.g., by forming triangles to the position of the mobile device from known points), based on measuring the radial distance, the direction and/or the strength, of a received signal at two or three different network devices.\n\nIn one or more embodiments, geographic positions of the mobile device are determined and tracked as a series of interactions occur between the mobile device and one or more network devices at the locale. In one or more embodiments, a geographic position of the mobile device is determined and tracked when the mobile device requests a connection to a network at the locale from a network device (e.g., a network device that is a wireless access point). For example, the request for a connection to the network may occur when a user of the mobile device initially approaches the locale (e.g., from an exterior zone of the locale). Additional geographic positions of the mobile device may be determined and tracked as the user moves within the locale and additional interactions occur between the mobile device and one or more network devices at the locale. For example, the mobile device may subsequently request data from a network device to access a local wireless network at the locale. Alternatively, a network device at the locale may, at periodic intervals, initiate communication with (e.g., ping) the mobile device while the mobile device is within range of the network device, to enable the determination of a geographic position of the mobile device. For example, an interaction may correspond to the movement of the mobile device between zones at the locale.\n\nIn block904, a metric for the locale using the geographic positions of the mobile device determined in block902above is calculated. In one or more embodiments, one or more geographic positions of the mobile device are used to calculate various quantities used to calculate the metric. For example, a metric that measures the amount of time spent by the mobile device at the locale may be calculated using a timestamp of an initial connection request from the mobile device and a timestamp at which the connection was terminated (or a timestamp at which the mobile device no longer responded to a request from the network device).\n\nIn one or more embodiments, the geographic positions of the mobile device are used to trace the movement of the mobile device within the locale. For example, the initial geographic position of the mobile device may be in an exterior zone where the mobile device first connects to a network of the locale. Then the geographic position of the mobile device may continue through various interior zones of the locale (e.g., an entrance zone, a shopping zone, and a checkout zone). Finally, the mobile device may exit the locale (e.g., when the mobile device terminates its connection to the network of the locale).\n\nAs another example, a metric that measures a register waiting time, or the length of a time interval during which a user of the mobile device waited in a checkout line at a register may be determined as follows. The starting point of the time interval may be the timestamp at which a geographic position of the mobile device was first within a pre-determined zone of the locale (e.g., a zone corresponding to the checkout line), as determined from an interaction (e.g., accessed from an event log of a network device) between the mobile device and a network device at the locale. For example, the pre-determined zone may be described in terms of a set of geographic positions. The ending point of the time interval may be the timestamp at which the geographic position of the mobile device was within a pre-determined threshold of the geographic position of a POS device (e.g., a POS device at the register in the checkout zone). Alternatively or additionally, the ending point of the time interval may be correlated with a timestamp of a sales transaction obtained from a POS device in the pre-determined zone (e.g., the geographic position of the mobile device was within a pre-determined threshold of the geographic position of the POS device at the same time a sales transaction was processed).\n\nIn one or more embodiments, a metric may measure the correlation of a volume of sales (e.g., at a specific register and/or POS device) within a time interval to the average wait time incurred by mobile devices in a checkout zone (e.g., corresponding to the register and/or POS device) within the time interval.\n\nAs another example, a metric may measure a walk-by conversion rate, or a fraction of customers (e.g., customers with mobile devices) entering the locale who complete a sales transaction may be determined as follows. The geographic position of each mobile device may be tracked, beginning with the first interaction between the mobile device and a network device at the locale. As described above, successive geographic positions within the locale may be tracked for each mobile device. If the geographic position of the mobile device is within a pre-determined threshold of a geographic position of a POS device at the locale, then it may be determined that the customer using the mobile device completed a purchase (e.g., as indicated in a sales transaction) at the locale. This determination may be confirmed if the geographic position of the mobile device remained with a threshold of the geographic position of the POS device for at least a pre-determined amount of time. In one or more embodiments, further confirmation of the purchase may be obtained by correlating a sales transaction from a sales log of the POS device with a sales transaction obtained from a mobile application of the locale executing on the mobile device as described below.\n\nAs another example, a metric that measures a walk-by conversion time, or the average amount of time between users (e.g., mobile devices) entering the locale and making a purchase may be determined by averaging the lengths of time intervals between mobile devices' entry to the locale and reaching (within a pre-determined threshold) the geographic position of the POS device.\n\nIn one or more embodiments, the value of a metric may be calculated over periodic time intervals, such as a day of the week and/or a time of day. In one or more embodiments, trends may be observed in the value of the metric relative to specific periodic time intervals. In one or more embodiments, a linear regression model may be used to detect trends in the historical values of the metric. In one or more embodiments, any other statistical model may be used to detect the trends in the value of the metric. In one or more embodiments, the trends may be used to predict the value of the metric relative to future periodic time intervals. For example, the value of the metric may have historically trended within a specific range on Monday mornings, and may therefore be predicted to continue trending within the specific range on subsequent Monday mornings. In one or more embodiments, a substantial deviation from a historical trend may be interpreted as an anomaly that may be discarded from analysis.\n\nAs another example, a metric that measures the size of walk-by traffic, or the number of mobile devices passing by the locale (e.g., on the sidewalk adjacent to the locale) may be determined by counting the number of mobile devices interacting with a network device at the locale, where the geographic position of the mobile device is in a specific zone of the locale (e.g., an external, sidewalk zone) within a time interval. Alternatively or additionally, the size of walk-by traffic may be measured by obtaining information from various sensors deployed at the locale (e.g., door chime sensors).\n\nThe size of the walk-by traffic may be measured for various time intervals, and substantial deviations from a historical trend may be interpreted as an anomaly to be discarded from analysis. For example, a spike in walk-by traffic may be due to a special event (e.g., a sports event or concert) or recurring event (e.g., a bus dropping off passengers) being held nearby.\n\nSimilarly, a metric that measures the size of a register (e.g., checkout) line, may be determined by counting the number of mobile devices whose geographic position is within a specific zone of the locale (e.g., a checkout zone) within a time interval. For example, an average size of a register line may be calculated for various (e.g., periodic) time intervals.\n\nIn a similar fashion, other metrics may be calculated using geographic positions of one or more mobile devices. Examples of other metrics may include an average amount of time spent in various zones of the locale (e.g., in a shopping zone, in a sidewalk zone external to the locale). In one or more embodiments, the value of a metric may be confirmed using information obtained from additional data sources (e.g., various sensors, a mobile application of the mobile device, POS device sales logs, etc.).\n\nFIG. 9Bshows a flowchart in accordance with one or more embodiments of the invention. In particular,FIG. 9Bshows a flowchart for correlating information from external sources with log entries for network devices in order to determine a metric. In one or more embodiments, the process described in reference toFIG. 9Bmay be practiced using one or more components described in reference toFIG. 1,FIG. 2,FIG. 6,FIG. 7,FIG. 8A,FIG. 8B,FIG. 8C, andFIG. 8D(e.g., the geographic positioning analyzer (814) described in reference toFIG. 8AandFIG. 8Dand the network device (808) described in reference toFIG. 8AandFIG. 8B). In one or more embodiments of the invention, one or more of the blocks shown inFIG. 9Bmay be omitted, repeated, and/or performed in parallel, or in a different order than the order shown inFIG. 9B. Accordingly, the scope of the invention should not be considered limited to the specific arrangement of blocks shown inFIG. 9B.\n\nInitially, in block910, events including interactions between a mobile device and one or more network devices on a network at a locale are accessed from a first data source. In one or more embodiments, the events include raw machine data associated with a timestamp. In one or more embodiments, the first data source may be an event log of the network device. Obtaining events may be performed in a same or similar manner as described above with reference to block900ofFIG. 9A.\n\nIn block912, external data from a second data source is received. In one or more embodiments, the second data source excludes the network devices. In one or more embodiments, the second data source is accessible via a network (e.g., a wireless network that is specific to the locale) that is separate from the network devices. In one or more embodiments, the second data source may be a POS device at the locale.\n\nObtaining information from the POS device may be direct from the point of sale device using an application programming interface of the point of sale device. By way of another example, sales logs from the point of sale device may be sent as unstructured raw machine data to the data intake and query system or indirect. In such a scenario, the search head may be queried for sales transactions matching a time frame in which the mobile device is located at the register (e.g., within the vicinity of the POS device). Because multiple sales transactions may exist at the time of the mobile device being in the register zone, a statistic about the multiple sales transactions may be attributed to the mobile device if a particular sales transaction cannot be attributed to the user of the mobile device. For example, after filtering any other sales transactions that can be attributed to other mobile devices or other users, the statistic may be generated. The statistic may be average of remaining sales transactions, the median of the remaining sales transactions or other statistics. As described above, the search head, after searching for the sales transactions, may calculate the statistic and return the statistic. By way of another example, the statistic may be generated by the geographic position analyzer.\n\nBy way of another example, sales logs may be sent from the POS device to a structured database that is distinct from the data intake and query system. In such a scenario, a query may be sent to the structured database to obtain the sales transaction information for the mobile device. In such a scenario, the structured database may respond to the query with attribute value pairs. Further, if the customer is part of a loyalty program or pays with any identifier of the customer and the customer can be assigned to the mobile device, then a particular sales transaction is assigned to the customer. If the mobile device cannot be directly or indirectly attributed to a particular sales transaction, then a statistic may be generated from the set of remaining sales transactions as described above. The statistic may be generated by the geographic position analyzer or by the structured database.\n\nContinuing with the examples of the second data source, in one or more embodiments, the second data source may be a mobile application executing on the mobile device. The mobile application may include user data corresponding to a user of the mobile device. In one or more embodiments, the user data includes previous sales transactions of the user (e.g., sales transactions occurring at the locale) and customer relationship management (CRM) data corresponding to the user. For example, the previous sales transactions of the user may include data on promotions redeemed by the user.\n\nIn one or more embodiments, the second data source may be a sensor at the locale (e.g., touch sensors, proximity sensors, optical sensors, door chime sensors, etc.). In one or more embodiments, a sensor may generate sensor data in response to an input or stimulus that may be used in determining a geographic position of a mobile device. In one or more embodiments, the second data source may be an inventory system that manages inventory items (e.g., products) at the locale. For example, the inventory system may track the quantities and expiration dates corresponding to each inventory item at the locale.\n\nIn block914, one or more geographic positions of the mobile device are determined, based on the interactions. Determining geographic positions may be performed as discussed above with reference to block902inFIG. 9A. In one or more embodiments, a geographic position may be related to a time interval of a mobile device at the geographic position. In one or more embodiments, the time interval may be a single point in time (e.g., corresponding to a timestamp obtained from an event log of a network device). In one or more embodiments, the time interval may be a range bounded by starting and ending points. For example, the mobile device may be assumed to be at a geographic position during the time interval bounded by a timestamp corresponding to a first interaction between the mobile device and a network device, and a timestamp corresponding to a second interaction between the mobile device and a network device.\n\nIn block916, the geographic positions and time intervals determined in block914above are correlated with the external data to obtain a metric. Also see description above of block904inFIG. 9A. Various metrics may be calculated based on correlating the geographic positions and time intervals with the external data. In one or more embodiments, the second data source is a POS device at the locale, and the metric may correlate a volume of sales (e.g., obtained from a sales log of the POS device) within a time interval to an average wait time incurred by mobile devices whose geographic positions are within in a checkout zone (e.g., corresponding to the POS device) within the time interval. That is, the average wait time incurred by mobile devices may be calculated using a succession of geographic positions within the checkout zone, where each geographic position corresponds to a time interval.\n\nIn one or more embodiments, the second data source is a sensor at the locale. For example, correlating sensor data obtained from a door chime sensor (e.g., attached to an entrance door of the locale) with the geographic positions and time intervals determined in block914above may be used in the calculation of a walk-by entry rate metric, or a fraction of customers passing by the locale who actually enter the locale. For example, geographic positions and corresponding time intervals may be determined for each mobile device (e.g., corresponding to a potential customer) moving between an exterior zone of the locale to an interior zone of the locale. The succession of geographic positions and corresponding time intervals may be used to determine what fraction of potential customers passing by the exterior of the locale actually enter the locale, and how long the customers remain at the locale. This information may be correlated with the sensor data obtained from the door chime sensor, which may track the number of potential customers entering the locale at various points in time. Correlating the different sources of information (e.g., the sensor data and the geographic position data) may yield a more accurate measurement of the metric than if a single source of information were used.\n\nBy way of another example, the correlation may relate the amount of time that a customer is in the locale with the total amount of the sales transaction. Statistics may be applied over several customers to determine whether a length of time that a customer is in a locale increases total amount sold, or the optimal amount of time for the customer to be in the locale. The correlation may be to determine where customers spend time in the locale.\n\nFIG. 9Cshows a flowchart in accordance with one or more embodiments of the invention. In particular,FIG. 9Cshows a flowchart for clustering mobile devices. In one or more embodiments, the process described in reference to FIG.9C may be practiced using one or more components described in reference toFIG. 1,FIG. 2,FIG. 6,FIG. 7,FIG. 8A,FIG. 8B,FIG. 8C, andFIG. 8D(e.g., the geographic positioning analyzer (814) described in reference toFIG. 8AandFIG. 8Dand the network device (808) described in reference toFIG. 8AandFIG. 8B). In one or more embodiments of the invention, one or more of the blocks shown inFIG. 9Cmay be omitted, repeated, and/or performed in parallel, or in a different order than the order shown inFIG. 9C. Accordingly, the scope of the invention should not be considered limited to the specific arrangement of blocks shown inFIG. 9C.\n\nInitially, in block920, a mobile device is identified based on events including interactions between the mobile device and a network device on a network at a locale. Obtaining events may be performed in a same or similar manner as described above with reference to block900ofFIG. 9A. In one or more embodiments, the events are accessed from an event log of the network device. In one or more embodiments, each event log entry of the event log includes a mobile device ID, which may be a MAC address of the mobile device. Each event log entry may also include a timestamp, and an interaction type.\n\nIn block922, geographic position patterns are generated for the mobile device using the interactions. As discussed above in the description of block902inFIG. 9A, in one or more embodiments, geographic positions of the mobile device are determined and tracked as a series of interactions occur between the mobile device and one or more network devices at the locale. In one or more embodiments, a series of successive geographic positions of the mobile device may correspond to movement of the mobile device within the locale (e.g., within various zones of the locale). In one or more embodiments, the geographic positions of the mobile device may be organized into geographic position patterns. Various techniques (e.g., machine learning techniques) for detecting patterns in a collection of data may be used when generating the geographic position patterns.\n\nIn block924, a characteristic of the mobile device is determined based on the geographic position patterns. In one or more embodiments, the characteristic may correspond to a behavior of a user of the mobile device. Specific characteristics may be of relevance from a retail perspective for segmenting customers (e.g., to determine which customers to target with which promotions). For example, a characteristic may correspond to spending a substantial amount of time in a specific zone at the locale (e.g., a lounge area, a specific shopping aisle, or promotional display zone), which may be useful information when considering which users to target for which types of promotions (e.g., coffee and snacks). Other examples of characteristics based on geographic position patterns may be: visiting the locale on average every N days (e.g., an \u201caverage return rate\u201d of N days), spending an average length of time of K minutes at the locale per visit, making a brief visit to the locale on most weekdays around lunchtime, visiting the locale on most Saturday mornings, etc. In one or more embodiments, the characteristic may be based on information obtained from a mobile application executing on the mobile device, including: percentage of promotions redeemed, total amount of sales, etc.\n\nIn block926, the mobile device is assigned to a cluster sharing the characteristic. In one or more embodiments, clustering techniques (e.g., k-means clustering, based on unsupervised machine learning techniques) may be used to group similar mobile devices into clusters where each member of the cluster is more similar (e.g., relative to the characteristic) to the other members of the cluster than to members of different clusters. In one or more embodiments, a membership score indicates the degree of similarity of a mobile device relative to the average value of the characteristic in the cluster. In one or more embodiments, the membership score of a mobile device in a cluster may be a percentage of the average value of the characteristic for the cluster. In one or more embodiments, grouping the mobile devices into clusters may be based on multiple characteristics.\n\nFIG. 9Dshows a flowchart in accordance with one or more embodiments of the invention. In one or more embodiments, the process described in reference toFIG. 9Dmay be practiced using one or more components described in reference toFIG. 1,FIG. 2,FIG. 6,FIG. 7,FIG. 8A,FIG. 8B,FIG. 8C, andFIG. 8D(e.g., the geographic positioning analyzer (814) described in reference toFIG. 8AandFIG. 8Dand the network device (808) described in reference toFIG. 8AandFIG. 8B). In one or more embodiments of the invention, one or more of the blocks shown inFIG. 9Dmay be omitted, repeated, and/or performed in parallel, or in a different order than the order shown inFIG. 9D. Accordingly, the scope of the invention should not be considered limited to the specific arrangement of blocks shown inFIG. 9D.\n\nInitially, in block950, a promotion for a product is selected. In one or more embodiments, the product may be a product category (e.g., coffee) or a specific product (e.g., cappuccino). In one or more embodiments, the product may be associated with an attribute (e.g., low fat). In one or more embodiments, the promotion and the product may be selected by an employee at the locale, to support the decision-making process regarding which promotions to run on which products. In one or more embodiments, the promotion may apply a discount to the product. In one or more embodiments, the product may correspond to an inventory item flagged by an inventory system of the locale whose expiration date is within a pre-determined time interval (e.g., an inventory item whose expiration date is the following day).\n\nIn block952, a time interval is selected for the deployment of the promotion. In one or more embodiments, the time interval may be selected based on historical sales data (e.g., obtained from sales logs obtained from POS devices at the locale) for the product at the locale. For example, a specific day of the week and time of day may be selected if that day and time typically corresponds with a low volume of sales for the product. In one or more embodiments, the time interval may be selected based on historical promotional redemption data (e.g., obtained from sales logs obtained from POS devices at the locale) for the selected promotion at the locale. In one or more embodiments, when the product corresponds to an inventory item whose expiration date is within a pre-determined time interval, then the time interval selected for the deployment of the promotion may be selected to be prior to the expiration date. Marketing personnel may select the time interval, the time interval may be preset as a default time interval, or the time interval may automatically be selected based on calculations using historical data.\n\nIn block954, target users are selected for the promotion. Selecting target users may be performed by querying the cluster data using characteristics or attributes of target users. Below are a few examples of characteristics or attributes that may be used when transmitting the query. In one or more embodiments, a user of the mobile device may be identified using a mobile application (e.g., a mobile application corresponding to the locale) executing on the mobile device that has access to information about the user. In one or more embodiments, the mobile application includes data on previous sales transactions of the user, include data on promotions redeemed by the user.\n\nIn one or more embodiments, the target users are members of a cluster whose characteristic correlates with a purchasing preference for the product. In one or more embodiments, the target users are members of a cluster whose characteristic correlates with a purchasing preference for the product category corresponding to the product. In one or more embodiments, the target users are members of a cluster whose characteristic correlates with a purchasing preference for an attribute (e.g., low fat) of the product.\n\nIn one or more embodiments, the target users are members of a cluster whose membership score exceeds a pre-determined percentage. In one or more embodiments, a target user may be physically proximate, as determined by a geographic position of the mobile device of the target user being within a threshold distance of a shopping zone of the locale in which the product is sold.\n\nIn one or more embodiments, the target users may include users who have demonstrated a proclivity to redeem promotions in the past. For example, the previous sales transactions of the user (e.g., obtained from a mobile application of the locale executing on the mobile device) may include data on promotions redeemed by the user.\n\nIn block956, an impact of the promotion is predicted using metrics. In one or more embodiments, the impact of the promotion is predicted based on trends in the values calculated for various metrics when the promotion was previously deployed. The trends may be determined from historical values in the current locale or in a different locale. In particular, if the promotion is applied to a second locale having a threshold degree of similarity to the current first locale based on attributes (e.g., geographic region, type of locale, type of products at locale, size of locale, etc.) of the second locale and the current first locale, then the metrics for the promotion at the second locale may be used. For example, sales transactions (including information on redeemed promotions) obtained from sales logs of the locale may be correlated with geographic positions to calculate various metrics, such as the various metrics described above with reference toFIGS. 9A and 9B.\n\nIf, in block958, the impact of the promotion is determined to be positive, then block960below is performed. Otherwise, if block958determines that the impact is not positive, then block950above is repeated, to select a different promotion.\n\nIf, in block960, specific users are targeted for the promotion, then in block962, the promotion is distributed to the targeted users. For example, the promotion may be distributed via email, text, via an alert in a mobile application executing on the mobile device, or using another transmission medium or combination thereof.\n\nOtherwise, if block960determines that specific users are not targeted for the promotion, then in block964, the promotion is distributed within the locale. For example, the promotion may be distributed using printed promotional materials, via audible announcements, via an alert in a mobile application executing on mobile devices in the vicinity of the locale, or using another technique.\n\nIn block966, an actual impact of the promotion is measured using metrics. In one or more embodiments, the impact of the promotion is measured by calculating various metrics and comparing the values of the metrics to the predicted values of the metrics of block956above.\n\nIn block968, corrective action is recommended to address any adverse operational impact of the promotion measured in block966above. For example, if the deployment of the promotion has resulted in longer lines and/or longer wait times at registers of the locale (see description of these metrics in block904above ofFIG. 9A), additional registers may be placed in service. As another example, if the POS device sales logs indicate that a substantial number of manager overrides have been required to process the promotion, then more experienced cashiers may be deployed to the registers (e.g., and additional training arranged for cashiers lacking experience with the deployed promotion). As another example, if the POS device sales logs indicate a substantial number of failed attempts to redeem the promotion, then technical support may be alerted to investigate potential hardware and/or software problems in processing the promotion. Finally, if the operational impact substantially adversely deviates from the predicted impact (e.g., of block956above), then the promotion may be canceled, and block950above may be repeated to select a different promotion.\n\nFIG. 10Ashows a flowchart in accordance with one or more embodiments of the invention. In one or more embodiments, the process described in reference toFIG. 10Amay be practiced using one or more components described in reference toFIG. 1,FIG. 2,FIG. 6,FIG. 7,FIG. 8A,FIG. 8B,FIG. 8C, andFIG. 8D(e.g., the geographic positioning analyzer (814) described in reference toFIG. 8AandFIG. 8Dand the network device (808) described in reference toFIG. 8AandFIG. 8B). In one or more embodiments of the invention, one or more of the blocks shown inFIG. 10Amay be omitted, repeated, and/or performed in parallel, or in a different order than the order shown inFIG. 10A. Accordingly, the scope of the invention should not be considered limited to the specific arrangement of blocks shown inFIG. 10A.\n\nInitially, in block1000, an interaction request is received from a mobile device. In one or more embodiments, the interaction request may be received by a network device. For example, the interaction request may be: a request to initiate a connection, a request to receive data, a request to send data, a request to terminate a connection, and/or any other request defined by a communication protocol.\n\nIn block1002, a mobile device ID is identified for the mobile device. In one or more embodiments, the mobile device ID may be obtained from the interaction request (e.g., from a packet received from the mobile device that includes the interaction request). In one or more embodiments, the mobile device ID may be a MAC address of the mobile device. Alternatively, the mobile device ID may be any identifier that uniquely identifies the mobile device.\n\nIn block1004, a new entry corresponding to the interaction request is appended to an event log. In one or more embodiments, the event log corresponds to the network device that received the interaction request in block1000above. In one or more embodiments, the new event log entry corresponding to the interaction request includes the mobile device ID, a timestamp, and the type of the interaction request. The new entry may be appended to the end of the event log for the network device.\n\nIn block1006, the interaction proceeds. In one or more embodiments, the network device proceeds with the interaction by transmitting a message to the mobile device. For example, the message may include an acknowledgment of the interaction request and/or requested data, etc., in accordance with a protocol, and depending on the type of interaction requested.\n\nIn block1008, a new entry corresponding to the performed interaction is appended to the event log. In one or more embodiments, the event log entry corresponding to the performed interaction includes the mobile device ID, a timestamp, and the type of the performed interaction. For example, the new entry may be appended to the end of the event log to denote success, completion, or failure of the interaction. Rather than each interaction having two entries in the event log, a single entry may be created for the start or end of the interaction.\n\nFIG. 10Bshows a flowchart in accordance with one or more embodiments of the invention. In one or more embodiments, the process described in reference toFIG. 10Bmay be practiced using one or more components described in reference toFIG. 1,FIG. 2,FIG. 6,FIG. 7,FIG. 8A,FIG. 8B,FIG. 8C, andFIG. 8D(e.g., the geographic positioning analyzer (814) described in reference toFIG. 8AandFIG. 8Dand the network device (808) described in reference toFIG. 8AandFIG. 8B). In one or more embodiments of the invention, one or more of the blocks shown inFIG. 10Bmay be omitted, repeated, and/or performed in parallel, or in a different order than the order shown inFIG. 10B. Accordingly, the scope of the invention should not be considered limited to the specific arrangement of blocks shown inFIG. 10B.\n\nInitially, in block1010, a request for information corresponding to a mobile device ID to be used in calculating a metric is received. In one or more embodiments, the request for information may be received by the geographic positioning analyzer. In one or more embodiments, the request for information may be received from an employee (e.g., a manager) of a locale. In one or more embodiments, the metric may be a metric discussed in the description of block904above inFIG. 9A. In one or more embodiments, the request for information may be sent during the execution of the processes described inFIG. 9A,FIG. 9B,FIG. 9C, andFIG. 9D.\n\nIn block1012, information from event logs, sales logs and/or external data is gathered. As discussed in the descriptions ofFIG. 9A,FIG. 9B,FIG. 9C, andFIG. 9D, information from event logs, sales logs and/or external data may be used in the calculation of various metrics that measure the performance of a locale (e.g., a retail store).\n\nIn block1014, the metric is calculated using the information gathered in block1012above. Calculating the metric may be performed as discussed above inFIG. 9A,FIG. 9B,FIG. 9C, andFIG. 9D.\n\n3.3. Examples\n\nThe following example is for explanatory purposes only and not intended to limit the scope of the invention.FIG. 11shows an implementation example in accordance with one or more embodiments of the invention.FIG. 11shows a layout of a locale (1100), in this case, a department store.FIG. 11shows various geographic positions (1102,1104,1106,1108) of a mobile device. Geographic position A (1102) is in an exterior (e.g., sidewalk) zone associated with the department store. Geographic position B (1104) is in an entrance zone associated with the department store. Geographic position C (1106) is in a shopping zone associated with the department store. Geographic position D (1108) is in a checkout zone (1110) where sales transactions are processed in the department store.FIG. 11also illustrates a lounge zone (1112) of the department store.\n\nThe following example is for explanatory purposes only and not intended to limit the scope of the invention.FIG. 12AandFIG. 12Bshow an implementation example in accordance with one or more embodiments of the invention.\n\nAs potential customers with mobile devices move within the vicinity of a department store (e.g., the department store shown inFIG. 11), various event logs (e.g., event log (1202)) track the interactions of the mobile devices with network devices on a network at the department store, as illustrated inFIG. 12A. There is a separate event log for each network device. Event log (1202) shows a series of interactions between a specific mobile device of a potential customer (Amy) and a specific wireless access point. Event log (1202) also includes interactions (not shown) between the mobile devices of other potential customers and the wireless access point. Each event log entry includes the mobile device ID of the mobile device, a timestamp, and an interaction type. The first event log entry in event log (1202) corresponds to a connection request from Amy's mobile device. This connection request occurred when Amy's mobile device initially moved within range of the wireless access point at geographic position A (1102) ofFIG. 11. Successive event log entries in event log (1202) correspond to other interactions (e.g., requests to receive data, requests to send data, data transmissions, etc.) between Amy's mobile device and the wireless access point. These interactions occurred as Amy traveled within the locale (e.g., at geographic position B (1104), geographic position C (1106), and geographic position D (1108) ofFIG. 11). Some of these interactions are initiated by the wireless access point (e.g., in order to periodically establish whether Amy's mobile device is still in the vicinity of the department store).FIG. 12Ashows only the entries corresponding to Amy's mobile device for simplicity purposes. Each customer and each device of each customer that is in the department store may have several entries in the same event log. Further, because entries are appended to the event log, the several entries of other customers are interspersed in the entries for Amy's mobile device. By way of an example, if fifty customers are in a store and each has at least one mobile telephone then at least fifty to two hundred or more entries may be present in the event log in which Amy's mobile device is only a small subset.\n\nThe manager of the department store decides to run a report that evaluates the performance of the department store based on several metrics. The geographic position analyzer is executed to calculate the metrics selected by the manager. The manager selects a register wait time metric. The manager also selects a time interval, in this case the previous day. Alternatively, the manager may have selected the previous Monday as the time interval, based on the observation that metrics exhibit seasonality tied to specific days of the week and/or times of the day. The geographic position analyzer determines, using the event logs for various network devices, the geographic positions of various mobile devices in the vicinity of the locale during the selected time interval. The geographic position data (1206) corresponding to Amy's mobile device used to calculate the register wait time is illustrated inFIG. 12B. Based on the geographic positions of the mobile devices, the geographic position analyzer determines a wait time interval beginning when a mobile device reached a geographic position at a line at a register and ending when the mobile device reached the geographic position of the register. For example, the geographic position data (1206) corresponding to Amy's mobile device shows that Amy's mobile device entered the line for register5at 1:25 pm and reached register5at 1:46 pm. The register wait time metric is then calculated as an average of the lengths of the wait time intervals for different mobile devices. The geographic positions may be confirmed by correlating a timestamp at which the mobile device was at the geographic position of the register with a timestamp in a sales transaction extracted from a mobile application of the department store running on the mobile device (e.g., the mobile application includes a history of the sales transactions corresponding to the user of the mobile device).\n\nAlthough satisfied with the overall performance of the department store regarding the various metrics, the manager of the department store then considers whether or not to run one or more promotions to improve sales. The geographic position analyzer is executed to predict the operational impact of various promotions selected by the manager. The manager selects a promotion that offers a free doughnut with a purchase of coffee. The impact of the promotion is predicted based on trends in the values calculated for various metrics (i.e., selected by the manager) in previous time intervals. Based on comparing the values of metrics in time intervals in which the promotion was deployed vs. the values of metrics in time intervals in which the promotion was not deployed, the geographic position analyzer predicts that deploying the promotion will increase the register wait time by fifteen percent (15%). Despite this prediction, the manager decides to run the promotion, but also authorizes the opening up of additional registers in an attempt to reduce the overall line size at each register. In addition, the manager assigns experienced cashiers to the additional registers to reduce the processing time of the promotions.\n\nAfter the promotion has been running for a few hours, the manager of the department store decides to evaluate, using the geographic position analyzer, the actual operational impact of the promotion. Based on the value of the register wait time metric in the most recent time intervals (e.g., of the past few hours), the geographic position analyzer discovers that the register wait time is substantially higher than expected. In addition, based on comparing the value of a promotion processing time metric in previous time intervals vs. the value of the promotion processing time metric in the most recent time intervals, the geographic position analyzer discovers that the promotion processing time is substantially higher than expected. The increase in the promotion processing time metric also correlates with information from sales logs of POS devices at the registers, which indicate an increase in manager overrides and failures associated with the promotion. In addition, the increase in the promotion processing time metric also correlates with the geographic positions of mobile devices remaining in the vicinity of the geographic position of the register for extended time intervals. The manager then suspends the deployment of the promotion, and alerts the technical support team to investigate potential hardware or software problems causing difficulty with the processing the promotion.\n\nWhile the invention has been described with respect to a limited number of embodiments, those skilled in the art, having benefit of this disclosure, will appreciate that other embodiments can be devised which do not depart from the scope of the invention as disclosed herein. Accordingly, the scope of the invention should be limited only by the attached claims.\n\n",
            "length": 135424
        },
        {
            "patent_id": "10936676",
            "text": "DETAILED DESCRIPTION\n\nOverview\n\nAs discussed above, biases in retrieved and indexed content, coupled with searchers' biases in how they examine and interpret search results, often lead searchers to incorrect answers to their questions. As used herein, \u201cbias\u201d means a situation where searchers seek or are presented with information that significantly deviates from the truth. \u201cTruth\u201d refers to information that is objectively verifiable and/or for which consensus has been obtained among authorities on the subject. For instance, for searches that are diagnostic (e.g., diagnosing a medical condition, home or auto repair, troubleshooting computer hardware or software, etc.), historical (e.g., recorded history), legal (e.g., relating to a law or regulation), or scientific (chemistry, biology, physics, math, astronomy, geology, etc.) in nature, \u201ctruth\u201d refers to a diagnosis, fact, law, or answer that is objectively verifiable and/or for which consensus has been obtained among authorities on the subject. In these instances, bias may be determined by comparison to one or more authoritative sources on the respective subject. By way of example and not limitation, in the case of medical diagnosis, Cochrane Reviews are an example of an authoritative source against which content may be compared to determine bias. As another example, in the case of automotive repair, a service manual of a vehicle manufacturer is an example of an authoritative source against which content may be compared to determine bias. These and numerous other authoritative sources may be used depending on the subject of the search queries.\n\nFor searches that are directed to topics, such as political views (as opposed to political history, voting records, or other objectively verifiable information) and religion, that are subject to opinion and/or for which there is no consensus, the concept of \u201ctruth\u201d may be relative (e.g., relative to some specified source such as religious text, political party manifesto, or the like) or may be inapplicable. In these instances, bias may be determined by comparison to the specified source, or may be indeterminate.\n\nIn the context of information retrieval or search, biases may be manifest in the way that a search engine indexes content, the way in which search results are ranked or presented, and/or the way in which users formulate search queries. Any or all of these sources of bias may affect the accuracy or veracity of content in search results, as well as the searchers' reliance on the search results. A recent study by the inventors of the subject application found that when searching for answers to diagnostic questions using conventional search techniques, users only obtained the correct answer about half the time. These results are significant, considering that people use the answers they obtain from search results to inform consequential decisions, such as self-treatment of medical conditions, repair of homes or vehicles, historical research, and others.\n\nThis application begins by describing techniques to detect biases or potential biases in search and retrieval. By observing content in a search engine index, retrieved by the search engine for particular queries, or selected by users, bias may be estimated in a number of ways. For instance, content in the search engine index may be compared with one or more authoritative datasets to determine whether or not the indexed content is representative of the content contained in the authoritative data sets. If not, the search engine crawler/indexer may be updated to crawl additional or alternative data that is more representative of the authoritative data sets. Additionally or alternatively, content in the search engine index may be reviewed by experts in the field (e.g., practicing medical professionals, auto mechanics, etc.). Labels may then be determined for the content (pages, result-page captions, advertisements, etc.). Labels may be determined through crowd sourced human assessments and/or by automatically extracting labels from documents. Presence of particular terms (e.g., alarming terms, colloquial terms, etc.) in result-page captions may be employed. These terms can be used to help explain deviations in aggregate click-through statistics across the top results, where deviations from the expected distributions are noted. This approach may also be leveraged as a means of estimating biases in both search result captions and in search behaviors (e.g., clicks associated with potential anxieties). Additional details and examples of detecting bias in search and retrieval can be found in the following article by the inventors of the subject application: Content Biases in Online Health Search, by R. W. White and A. Hassan, published in ACM Transactions on the Web (TWEB), Volume 8, Issue 4, Article 25, Nov. 6, 2014.\n\nOnce bias or potential bias is detected, this application describes techniques that may be applied to indicate and/or compensate for the bias. Such techniques may allow users to more easily assess the veracity of search results, and increase the chances that users will locate accurate answers to their questions. Additionally, providing users with search results that are more accurate and authoritative, will reduce number of search queries submitted and the number of search results reviewed to arrive at an answer, thereby reducing overall network traffic per obtained answer. Furthermore, in some examples, by modifying a crawling strategy, search engines may crawl the web more efficiently. This also will reduce the overall network traffic by capturing more authoritative content and avoiding unnecessarily crawling inaccurate, redundant, and/or unauthoritative content on the web.\n\nIn some examples, techniques described herein may be applied to detect and/or compensate for generalized biases of search users in aggregate, without regard to beliefs of individual users. The way in which search results are presented may influence user click through behavior (i.e., which entries of the search results the user reviews and in what order). For instance, user click through behavior tends to be skewed to favor result entries that are presented near the top of the search results, that are phrased in the affirmative (e.g., symptom X is caused by condition Y), and/or that include references to potentially alarming content such as serious medical conditions (e.g., heart attack, stroke, etc.) or extensive or catastrophic diagnoses (engine ceased, hard drive crashed, etc.). Furthermore, content itself may be objectively untrue/inaccurate and, thus, biased. Content from authoritative sources or that uses authoritative terminology (e.g., \u201ctreat\u201d or \u201crepair\u201d) tends to be more objectively accurate than content from non-authoritative sources or that uses colloquial terms (e.g., \u201chelp\u201d or \u201cfix\u201d). Taking into account these generalized biases, modified search results that compensate for the generalized bias(es) may be generated and output for presentation at a client device of the user. For instance, example techniques may include detecting terms (e.g., alarming terms, colloquial terms, etc.) in captions of search result entries that are likely to skew user click-through behavior, and replacing such entries with other entries that have substantively similar content but are free of the detected terms.\n\nIn some examples, multiple sets of search results may be obtained using multiple different ranking algorithms. For instance, one ranking algorithm may be used to generate a set of search results that takes into account the veracity of the search results, and another ranking algorithm may disregard veracity of the results. Alternatively, one ranking algorithm may weight popularity of results more heavily than veracity of the results, and another ranking algorithm may weight veracity of results more heavily than popularity of the results. The multiple sets of search results may be output for presentation concurrently or sequentially at a client device of the user.\n\nIn some examples, techniques may include obtaining search results responsive to a search query, and detecting one or more potentially biased entries from among the multiple entries of the search results. The search results may be annotated with an indication of the potentially biased entries. In some examples, the indication may include a visual indicator presented in association with each of the one or more potentially biased entries. In some examples, the indication may include one or more normative base rates indicating a likelihood of a condition given one or more symptoms. The search results may be output for presentation at a client device of the user along with the indication of the potentially biased entries. In this way, users may be made aware of potentially biased entries and may take into account the potential bias when deciding which entries of the search results to review and/or when answering a question related to the query.\n\nThe techniques described herein may be implemented in whole or in part by one or more search engine servers. In some examples, certain techniques (or portions thereof) may be implemented at a client device of a user performing a search and/or by another computing device (e.g., an intermediary web service). By way of example and not limitation, illustrative systems and devices suitable for implementing the techniques are described below with reference to the figures.\n\nExample Architecture\n\nFIG. 1is a schematic diagram of an example architecture100that introduces illustrates techniques for detecting, indicating, and/or compensating for bias in search. WhileFIG. 1illustrates an example in which multiple different techniques used together, in other examples the various techniques may be used individually and/or in different combinations. Additional details of individual operations illustrated inFIG. 1are described in more detail with reference to subsequent figures.\n\nThe architecture100includes a client device102(sometimes referred to as a \u201ccomputing device102\u201d) which is in communication with a search engine104. As shown, a user106is performing a search via the client device102. The user106has one or more beliefs and biases108. These beliefs and biases108may be common among users, or may be unique to the particular user. A user's beliefs influence how they formulate their search queries (e.g., how they frame search queries, the terms they use in search queries, etc.). For example, people typically frame questions positively/affirmatively (e.g., \u201cCan acid reflux cause back pain?\u201d and not \u201cIs acid reflux unrelated to back pain?\u201d). This framing can reveal something about their preconceptions, but can also skew search engines if people also phrase their search queries positively. As an example, ranking methods may consider a result with a yes-oriented answer (e.g., \u201cAcid reflux can cause back pain\u201d) to be more similar to the query than a no-oriented answer (e.g., \u201cAcid reflux cannot cause back pain\u201d). Thus, the framing of search queries can significantly impact search results returned, so any bias in the search queries will likely lead to a bias in the retrieved results.\n\nAlong with the framing, the terms used in the search query also dictate the results that will be returned. Certain terms are more likely to result in accurate information than others. Thus, the choice of terms used in the search query affects the accuracy of the search results. This is true even for synonyms or near synonyms. This is also related to the nature of the document (e.g., authoritative results are more likely to use the term \u201ctreat\u201d rather than \u201chelp\u201d). Thus, accuracy of search results may be improved and bias may be minimized by improving the search query upon which the search is performed.\n\nFIG. 1illustrates an example in which the user106enters a search query110via an interface of a web page, browser, operating system or application of the client device102. The search query110may be composed of multiple terms (e.g., \u201cCan tea tree oil help athlete's foot?\u201d). This search query110will produce a set of search results which is likely to be skewed in favor of affirmative results (since the search query was framed in the affirmative). Also, certain terms used in the query (e.g., \u201ccan\u201d and \u201chelp\u201d) are colloquial and tend to be associated with results that are less authoritative. Thus, the results based on this query110may not be accurate and, therefore, may be biased.\n\nFIG. 1illustrates several example techniques that may be used to alter the search query to improve accuracy of search results. In a first example, at112, the search engine104or the client device102may provide suggested alterations to the query to improve the accuracy of search results, which the user may accept or reject. The suggested alterations112may be provided in the form of substitute term suggestions (e.g., use \u201cdoes\u201d instead of \u201ccan\u201d and \u201ctreat\u201d instead of \u201chelp\u201d to obtain more authoritative results). In that case, a list of substitute terms may be maintained in memory of the search engine104, the client device102, or both, and may be updated over time to include additional or alternative terms. Additionally or alternatively, suggested alterations112may be provided in the form of questions to help the user refine the search query (e.g., \u201cDo you want to know if tea tree oil is an effective treatment for athletes' foot?\u201d). In that case, machine learning techniques may be employed to discern the user's intent and to feedback the reformulated query to the user for confirmation. Additionally or alternatively, at block114, the search engine104or the client device102may employ \u201cbackend\u201d query alterations (hidden from the searcher) to replace terms that could introduce skew into the results, such as \u201ccan\u201d and help,\u201d with synonyms such as \u201cdoes\u201d and \u201ctreat.\u201d The output of the suggested alteration112and the backend query alteration114is an altered query116. The suggested alteration112and/or the backend query alteration114may be updated over time using machine learning to optimize the query suggestions/alterations based on individual and/or aggregate search behaviors responsive to receiving results based on the altered search query116.\n\nThe altered query116is then provided as an input to one or more ranking algorithms118. The altered query116may also be provided to a search engine index120, which may return results122based on the altered query116. In other examples, the suggested alteration112and query alteration114may be omitted, in which case the original search query110may be provided to the ranking algorithm(s)118and search engine index120.\n\nThe ranking algorithm(s)118may include multiple ranking algorithms that take into account different factors and/or weight different factors differently. For instance, some ranking algorithms focus on satisfying searcher desires (validation) versus providing them with a correct answer (veracity). Ranking algorithms that focus on validation may weight popularity of search results more heavily than veracity of search results, or may ignore veracity of the search results entirely. The search engine104may determine which of the ranking algorithm(s)118to use to rank results120. This determination may be made globally for all queries (e.g., always prefer veracity), based on the subject matter (e.g., favor veracity for certain topics such as healthcare, or those where there is a known and accepted truth, but for more controversial topics such as politics or religion prefer validation since there is no clear truth), or based on user models reflecting individual user preferences (e.g., searchers may want their beliefs to be validated, irrespective of factual correctness). The selected ranking algorithm(s)118are used to obtain ranked results124. In some examples, the search engine104may apply multiple ranking algorithms118to obtain multiple sets of ranked results124.\n\nIn some examples, the ranked results124may be transmitted to the client device102for presentation to the user without further modification. Additionally or alternatively, the ranked search results124may be further modified, at a result modification operation126, prior to being output to the client device102for presentation to the user106. The result modification operation126may include modifications to indicate and/or compensate for generalized bias of aggregate users and/or to compensate for individualized bias of individual users.\n\nIn the case of generalized bias of aggregate users, the result modification operation126may include replacing a search result entry having a first term (e.g., a term previously determined to be \u201calarming\u201d or \u201ccolloquial\u201d) in the caption with another entry having substantively similar content but having a caption that is free of the first term. The replacement caption may, for example, use a second term, which has previously been determined to be authoritative, instead of the first term.\n\nAdditionally or alternatively, the result modification126may include appending an annotation to the search results indicating that one or more entries of the ranked search results124are potentially biased. In some examples, in which the search query relates to diagnosing a condition, the annotation may include one or more normative base rates, which indicate a likelihood of the condition given one or more symptoms. These annotations of potentially-inaccurate or potentially biased content, may be helpful to the user in guiding both search interaction decisions and real world decisions more generally. In some examples, the annotations may be presented interactively (e.g., as interactive controls presented on a graphical user interface of the search results page), allowing users to select the controls to gain additional information (e.g., a description of why the entry was flagged as being potentially biased, suggestions for how to obtain more authoritative information, etc.). In examples in which the annotations include normative base rates, the controls may allow the user to provide additional information about the symptoms they are experiencing (e.g., by selection of one of the listed symptoms or by inputting text via a text box) to refine the search and/or allow the user to select one or more symptoms to obtain lists of other conditions that also result in the selected symptom(s). As discussed further below, such techniques can also be used to collect information about the preferences of users that can be useful in refining their queries and in constructing long-term models of their beliefs for use in personalizing the search experience.\n\nAdditionally or alternatively, the result modification126may include determining a potential bias of each entry of the ranked results124, and reordering the ranked results124based on the potential bias to present entries having least potential bias first.\n\nIn the case of individualized bias, the result modification126may take into account a belief model128of the user, which comprises information about the user's beliefs108and preferences, and may be used to determine and potentially compensate for the user's biases. Because beliefs are highly personal, user consent may be obtained prior to collecting user belief information. The consent may be obtained by presenting a notification to the user allowing the user to opt-in or -out of the belief modeling service. Alternatively, depending on the information to be collected, in some instances user consent may be obtained as part of the terms and conditions for use of the web site, browser, operating system, or application through which the user accesses the search engine104.\n\nThe belief model128may be generated and refined based on explicit beliefs and/or preferences130provided by the user (e.g., in response to questions, prompts, settings, or other information presented to the user via the client device102). For instance, the beliefs and preferences130may include information collected prior to performing a search, such as when the user106registers for, or manages, an account with a service provider that hosts the search engine (e.g., an email account, a social networking account, an e-commerce merchant account, a payment account, etc.). Additionally or alternatively, the beliefs and preferences130may include information collected subsequent and/or responsive to the user106submitting the search query110. For instance, beliefs and preferences130may include user input received in response to the suggested query alterations112(e.g., accepting or rejecting suggested query alterations, responses to questions aimed at refining the search query, etc.). Examples of beliefs and preferences130that the user may explicitly provide include registration information (e.g., name, login, password, contact information, etc.), demographic information (e.g., age, gender, address, occupation, education, income, etc.), payment information (e.g., account numbers, financial institutions, etc.), preference information (e.g., shipping preferences, content preferences, interests, etc.), and the like. This information may be provided at the initiative of the user (e.g., in order to take advantage of certain services) and/or may be provided in response to a prompt for the information.\n\nThe belief model128may additionally or alternatively be based on beliefs inferred from historical data132, such as historical search queries, search results corresponding to the historical search queries, interaction with the search results (e.g., clicks, order of clicks, hovers, lengths of time that search result entries were viewed, etc.), browser history, purchase history, social networking information (e.g., connections, posts, etc.), etc. The historical data132may comprise information stored locally at the client device102, information related to or obtained by a service provider or entity that administers the search engine104, or information from one or more other service providers or entities.\n\nThe explicit beliefs and preferences130and the historical data132may be provided to a belief modeling operation134to generate the belief model128for the user. The belief modeling operation134may be performed iteratively over time to optimize the belief model128using machine learning techniques.\n\nUsing the belief model128, the result modification operation126may model user's degree of belief in one more subjects relevant to the search query and personalize the search results based on the belief. Current approaches to personalization focus on topical matches (e.g., knowledge that a user is interested in content on a particular topic, rather than their degrees of belief in particular outcomes associated with that topic, which can influence behaviors, search satisfaction, and overall search success). By taking into account the user's beliefs, the search engine104may modify the ranked results124to compensate for biases of the user related to the beliefs. For instance, the result modification126may include surfacing content to provide context for the results (e.g., content providing background or foundational information, or content interpreting or elaborating on the search results) or to counter erroneous beliefs (e.g., content refuting or debunking the erroneous belief).\n\nThe result modification operation126, may then output modified results136(in addition to or instead of ranked results124and/or preliminary results122) for presentation by the client device102. As noted above, the modified results136may be modified to compensate for generalized biases of aggregate search users, individualized biases of the user106, or both.\n\nThe user106may then view the modified results136including any annotations (e.g., indications of bias, base rates, etc.). Upon viewing the modified results136, the user106may interact with the modified results136in a variety of ways. For instance, the user106may scroll through the results, hover a pointer over one or more result titles or captions, click on or otherwise select one or more result entries, or the like. Additionally, the user may interact with the annotations indicating bias of one or more entries and/or indicating normative base rates, as described above. The user's client device (or a browser, operating system, or application thereof) may monitor and collect this result interaction138and feed it back to the search engine104to optimize the result modification126for the user106. By way of example, the search engine104may use the result interaction138information to optimize personalization of future search results, update the belief model128, or the like.\n\nThe user's search behavior140, including the original search query110, altered query114, results (modified results136, ranked results124, and/or results122) and/or result interaction138, may be aggregated with search behavior of other users at an aggregation operation142. Additionally or alternatively, the user's belief model128may be aggregated with belief models of other users at the aggregation operation142. The aggregation operation142may be performed by the search engine104and/or by one or more third party services. In the process of the aggregation operation142, the search behavior and belief model of the user may be de-identified. The aggregate search behavior and belief models144may be fed back to an implicit feedback debiasing operation146to compensate for generalized bias(es) represented by the aggregate search behavior and belief models144. The user's interactions with the search results (result interaction138) may also be fed back to the implicit feedback debiasing operation146. The interactions from this user108with the search results (result interaction138) and other users (aggregate search behavior and belief models144) represent combined properties of the search engine results (e.g., the presence of alarming content in captions selected by the users) and their long-term behaviors to better understand the motivations behind the users' clicks. This can be used to de-bias the click information and provide a cleaner signal to the ranking algorithm(s)118for offline training148when aggregated across many searchers.\n\nBiases may also be manifest in a search engine index due to the way in which content is crawled and/or indexed. Search engines index particular parts of the web. The content that is indexed can be strongly skewed toward particular outcomes (e.g., a lot more written in support of a treatment option than against it). This may be appropriate when the correct answer agrees with the skew, but is problematic when there is a lack of agreement. The skew in crawled and indexed content may reflect aggregated preferences in the nature or source of information that searchers seek, or general availability of the content on the web. Search engines optimize content (including learned rankings and resource selection) for the types of questions that users typically ask rather than normative base rates. In some examples described herein, the search engine104may take into account the quality/accuracy of content in crawling and indexing decisions. This may increase accuracy by reducing the strong positive skew in results and index content.\n\nReferring back toFIG. 1, a search engine crawler150crawls web content152, which is indexed by an indexer154and stored in the search engine index120. However, if the crawler150is configured to disproportionately crawl inaccurate or unauthoritative content (e.g., content skewed toward particular outcomes), and the indexer154indexes that content, then the search engine index120will propagate this. By detecting this bias, the crawler150can be updated to search additional external knowledge bases156containing information about incidence rates and the authoritativeness of the content available. Additionally or alternatively, the crawler150may be configured to crawl additional authoritative sources of content and/or to crawl authoritative sources more thoroughly (e.g., to a deeper level of linking). In some instances this may include obtaining subscriptions or license rights to access the additional authoritative content. In some examples, if authoritative content on a particular subject is unavailable, the search engine104may commission the creation of new content by an authority on the subject. In addition to modifying the crawler, in some examples, the indexer154may be modified to index content differently to compensate for bias. For instance, the index may be modified to index authoritative content more thoroughly (e.g., including a higher density or finer granularity of index entries for authoritative content). Bias can be detected at various stages of the search process. These and other modifications to the crawling and indexing of content may increase the accuracy, and thereby reduce an extent of bias, of search results.\n\nIn some examples, a bias measurement operation158may be performed by periodic probes160of the search engine index120, ranking algorithm(s)118(or the incoming results122or outgoing ranked results124), result modification126(or modified results136), or other operations of the search engine104.\n\nExample Search System\n\nFIG. 2is a schematic diagram illustrating an example system200of devices usable to implement techniques for detecting and/or compensating for bias in search.FIG. 1illustrates a conceptual flow of operations for detecting, indicating, and/or compensating for bias in search,FIG. 2illustrates additional details of hardware and software components that may be used to implement such techniques. The system200is merely one example, and the techniques described herein are not limited to performance using the system200ofFIG. 2. The system200includes the client device102and the search engine104.\n\nIn the example ofFIG. 2, the client device102includes one or more processors202and memory204communicatively coupled to the processor(s)202. The client device102may be implemented as any type of computing device including, but not limited to, a personal computer, a laptop computer, a tablet computer, a portable digital assistant (PDA), a mobile phone (e.g., a smart phone), an electronic book (e-book) reader, a game console, a set-top box (STB), a smart television (TV), a portable game player, a portable media player, and so forth.FIG. 2shows representative client devices102in the forms of a desktop computer102(1), a laptop computer102(2), a tablet102(3), and a mobile device102(M). However, these are merely examples and client devices102according to this application may take other forms.\n\nThe client device102may include a browser206and one or more applications208stored in the memory204. The client device102may also include one or more communication connections210by which the client device102is able to communicate with other devices over a network212. The browser206may be usable to access one or more search engines, including search engine104, and other sites (e.g., e-commerce merchants, content providers, social networking sites, etc.) via the communication connections210over the network212. In some examples, the browser206may include a search interface (e.g., search box or bar) by which a user can enter a search query via the search interface without navigating to a particular search engine or website.\n\nExamples of the application(s)208stored in the memory204include an operating system, a virtual assistant (e.g., Siri\u00ae available from Apple Inc. of Cupertino Calif. or Cortana\u00ae available from Microsoft Corporation of Redmond Wash.), a social networking application, a media player, a game, an email or messaging application, a word processing application, a shopping application, or the like. Some or all of the applications may include search functionality usable to search public and/or private corpuses of documents.\n\nThe search engine104may be implemented or hosted by one or more servers, server farms, data centers, or other computing devices. In the illustrated example, the search engine104is implemented by multiple servers214(1),214(2), . . . ,214(Q) (collectively \u201cservers214\u201d), where Q is any integer greater than or equal to 1. The search engine104includes one or more processors216communicatively coupled to memory218. Memory218may include one or multiple memory devices. The search engine104also includes one or more communication connections220by which the search engine104is coupled to the network212. In the illustrated example, the memory218stores the aggregate search behavior and belief models144collected from multiple searchers over time. As discussed above, the aggregate search behavior may include search and browsing histories of multiple users over time including, for example, search queries and corresponding search results, captions of search results, user interactions with the results (e.g., result clicks, hovers, scrolling, time spent viewing individual results, order in which results are viewed, etc.). The belief models may include information about beliefs and preferences of users gleaned from their individual and/or aggregate search behaviors.\n\nA belief modeler222may perform the belief modeling operation134to generate the belief model128for the user. The belief modeler222may employ machine learning224to optimize the belief models128over time as individual users perform additional searches and interact with the results of such searches. While the machine learning224in this example is shown as a separate module, in other examples, machine learning logic may be incorporated in the belief modeler222.\n\nA search customizer226may perform the query alteration114, result modification126, and/or implicit feedback debiasing146. The search customizer226may take into account generalized biases of aggregate users and/or individualized biases of a particular user derived from his or her belief model128, and may customize search results to compensate for such biases. As discussed above, compensation for bias may include, for example, selecting which content to include in the search results, selecting or modifying an order in which to present the search results, presenting annotations indicating potential bias or providing an objective context against which searchers can consider the search results.\n\nThe memory218also stores the crawler150, indexer154, search engine index120, and ranking algorithm(s)118, and a bias monitor228which performs the bias measurement operations158. For instance, bias monitor228may perform the periodic probes160of the search engine index120, ranking algorithm(s)118(or the incoming results122or outgoing ranked results124), result modification126(or modified results136), or other operations of the search engine104. In the event that the bias monitor228identifies bias in one or more components of the search engine104, the bias monitor228may initiate one or more actions to compensate for the bias. For example, if the bias monitor228determines that the search engine index120contains content that is inaccurate, unauthoritative, is not representative of the truth, and/or omits relevant or authoritative content, the bias monitor228may update a crawling strategy to cause the crawler150to crawl additional or alternative content to compensate for the bias. Additionally or alternatively, the bias monitor228may update an indexing strategy to cause the indexer154to index the crawled content differently to compensate for the bias. The bias monitor228may leverage the machine learning224to optimize the crawling and/or indexing strategies over time based on the aggregate search behavior and belief models144for example.\n\nThe bias monitor228may additionally or alternatively identify bias in one or more of the ranking algorithms118. The bias monitor228may leverage the machine learning224to update one or more of the algorithms and/or generate new algorithms in order to compensate for bias. For instance, the ranking algorithm(s)118may include an algorithm that takes into account veracity of search results and ranks search results based at least in part on veracity. In some examples, such an algorithm may weight veracity of the results more heavily than popularity of the search results. The veracity of results may be reevaluated and updated over time based on user search behavior and/or comparison to authoritative sources of content. In some examples, the ranking algorithm(s)118may include one or more algorithms that are customized for individual users (e.g., a unique, custom algorithm for each user), customized for classes of users (e.g., an algorithm for academic users, an algorithm for medical users, an algorithm for authors, an algorithm for users from a predetermined location, etc.), customized for different query types (e.g., diagnostic queries, opinion based queries, entertainment queries, etc.), or the like.\n\nThe processor(s)202and216may be configured to execute instructions, applications, or programs stored in the memories204and218, respectively. In some examples, the processor(s)202and/or216may include hardware processors that include, without limitation, a hardware central processing unit (CPU), a graphics processing unit (GPU), a field programmable gate array (FPGA), a complex programmable logic device (CPLD), an application specific integrated circuit (ASIC), a system-on-chip (SoC), or a combination thereof.\n\nThe memories204and218are examples of computer-readable media. Computer-readable media may include two types of computer-readable media, namely computer storage media and communication media. Computer storage media may include volatile and non-volatile, removable, and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, or other data. Computer storage media includes, but is not limited to, random access memory (RAM), read-only memory (ROM), erasable programmable read-only memory (EEPROM), flash memory or other memory technology, compact disc read-only memory (CD-ROM), digital versatile disk (DVD), or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other non-transmission medium that may be used to store the desired information and which may be accessed by a computing device, such as client device102or servers214. In general, computer storage media may include computer-executable instructions that, when executed by one or more processors, cause various functions and/or operations described herein to be performed.\n\nIn contrast, communication media embody computer-readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave, or other transmission mechanism. As defined herein, computer storage media does not include communication media.\n\nAdditionally, the communications connection(s)210and220include physical and/or logical interfaces for connecting the respective computing device(s) to another computing device or a network. For example, the communications connection(s)210and220may enable WiFi-based communication such as via frequencies defined by the IEEE 802.11 standards, short range wireless frequencies such as Bluetooth\u00ae, or any suitable wired or wireless communications protocol that enables the respective computing device to interface with the other computing devices.\n\nThe architectures, systems, and individual elements described herein may include many other logical, programmatic, and physical components, of which those shown in the accompanying figures are merely examples that are related to the discussion herein.\n\nExample Query Modification\n\nFIG. 3AandFIG. 3Bare flow diagrams of example process300of reformulating a search query to compensate for bias. The process300may be performed as a backend query reformulation by a computing device such as a search engine (e.g., search engine104), as a local query reformulation by a client device (e.g., client device102), or by a combination of backend and local operations.\n\nWhen performing a search, a user (e.g., user106) inputs a search query via a search box. In some examples, the user may access the search box by navigating to a search engine web site (e.g., Bing\u00ae, Google\u00ae, Yahoo! \u00ae, etc.) or another web site having search functionality (e.g., a social networking site, application store, micro blogging site, e-commerce merchant website, etc.). In other examples, the search box may be included as part of a browser (e.g., interface, toolbar, menu, add-on, plug-in or the like).\n\nAs shown inFIG. 3A, at operation302, the computing device (e.g., search engine104or client device102) receives the search query. The search query includes one or more search terms that were input by the user. The search terms may comprise textual search terms, images, or audio search terms, and may have been input by the use using a keyboard or other text input device, a camera or other image capture device, or a microphone or other audio input device, respectively.\n\nAt operation304, the computing device detects one or more biasing terms from among the one or more search terms. The biasing terms are terms that have previously been determined to bias search results. Whether or not particular are biasing terms may be determined in a variety of ways. In one example, biasing terms may be determined empirically by inputting a candidate term, obtaining search results for the candidate term, and comparing content of the obtained results to see if the content is accurate (i.e., does not significantly deviate from the truth). In this example, the accuracy of the content may be determined by comparison to one or more authoritative sources (e.g., Cocheran Reviews in the example of medical diagnosis) and/or by review by one or more authorities on a subject (e.g., medical experts or practitioners, continuing the example of medical diagnosis). If a predetermined portion of the search results (e.g., 25%, 33%, a majority, 66%, etc.) and/or if j of the top k search results (e.g., 2 of the top 3, 3 of the top 5, 7 of the top 10, etc.) are accurate, then the candidate term may be determined not to be a biasing term. In this example, j is the number of accurate results out of a set of k top search results, where k is greater than or equal to j. In contrast, if the predetermined portion of the search results are not accurate and/or if j of the top k results are not accurate, then the candidate term may be determined to be a biasing term. For each biasing term, one or more synonyms may be determined. Synonyms may be determined, for example, using a thesaurus, based on analysis of similar search queries, or the like. A list of biasing terms and their synonyms may be generated and updated over time using machine learning (e.g., machine learning224) and stored in memory of the computing device (e.g., memory218and/or204).\n\nAt operation306, the computing device alters or reformulates the search query to generate a reformulated search query designed to compensate for bias. In some examples, the query may be reformulated automatically by substituting the biasing term(s) with synonyms (that are non-biasing) from the list of biasing terms and their synonyms stored in memory of the computing device. In some examples, reformulating the search query may comprise replacing colloquial terms with terms having substantially same meanings as the colloquial terms but previously having been determined to be more authoritative than the colloquial terms. For instance, the computing device may replace the term \u201chelp\u201d (a colloquial term previously determined to result in inaccurate and/or unauthoritative results) with the term \u201ctreat\u201d (previously determined to return more authoritative results than the term \u201chelp\u201d). In some examples, reformulating the search query may comprise replacing affirmatively skewed terms (i.e., terms that imply an affirmative relationship between other terms in the search query) with neutral terms (i.e., terms that do not imply an affirmative relationship between the other terms in the search query). For instance, the computing device may replace the term \u201ccause\u201d (which implies an affirmative or causal linkage between terms) with \u201cand\u201d (which implies no such linkage). In some examples, reformulating the search query may comprise replacing equivocal terms with unequivocal terms. For instance, the computing device may replace the terms \u201ccan\u201d and \u201cmay\u201d (which are equivocal) with \u201cdoes\u201d (which is unequivocal).\n\nAt operation308, the computing device may obtain search results based at least in part on the reformulated/altered search query and, at operation310, outputs the results for presentation to the user. In the case where query reformulation is a backend operation performed by the search engine, obtaining the search results comprises referencing a search engine index to obtain results and ordering the results using a ranking algorithm stored in the memory of the search engine. Outputting the search results for presentation to the user in such an example comprises transmitting the search results via communication connections to the client device for presentation of the search results on a display of the client device. In the case where the query reformulation is a client side operation performed by the user's client device, obtaining the search results comprises transmitting the reformulated search query to a remote search engine to perform a search based on the reformulated search query, and receiving the search results from the remote search engine. In such an example, outputting the search results for presentation to the user comprises displaying the search results on a display of the client computing device.\n\nFIG. 3Billustrates operations following output of the search results for presentation to the user. Upon being presented with the search results, the user may interact with the search results. For instance, the user may scroll through the search results, may hover a pointer or other selection device over a search result, click on one or more of the search results to view the respective search results, or the like. The search engine (or client device) may monitor and collect this search behavior (with user permission) and use it (alone or aggregated with other user search behavior) to refine various aspects of the search process, such as query reformulation, search result ranking, search result selection, or the like.\n\nAs shown inFIG. 3B, at operation312, the computing device receives click-through data input by the user responsive to the search results. From this click-through data, the computing device may, at operation314, infer one or more beliefs of the user. The beliefs may be inferred based on the click-through data with or without reference to a belief model of the user (e.g., belief model128). At operation316, the computing device may update a ranking algorithm, crawler, indexer, and/or index of the search engine based on the one or more beliefs of the user. For instance, the computing device may update the ranking algorithm to weight results differently and/or present results in a different order in order to compensate for bias apparent from the beliefs of the user.\n\nSubsequently, the user may input an additional search query, which the computing device receives at operation318. At operation320, the computing device may obtain search results based on the additional search query and the one or more beliefs of the user. These search results may be output, at operation310, for presentation to the user.\n\nFIG. 3AandFIG. 3Bdescribe an example process of automatic query reformulation.FIG. 3Cillustrates another technique for reformulating a search query that takes into account user input in reformulating search queries. As shown in this example, the operation306of reformulating the search query includes presenting a user interface322suggesting alterations to the query to improve the accuracy of search results, which the user may accept or reject. The suggestions may be based on the search query terms input by the user, search behavior of other users (e.g., queries, results, and interactions with results), previous search behaviors of the user, a belief model of the user, and the like. If the user accepts the suggested alterations, the computing device may reformulate the query based on the user acceptance of the suggested query alteration. In the illustrated example, the suggestions take the form of questions to help the user refine the search query (e.g., \u201cDo you want to know if tea tree oil is an effective treatment for athletes' foot?\u201d). However, in other examples, the suggestions may be provided in the form of substitute term suggestions (e.g., use \u201cdoes\u201d instead of \u201ccan\u201d and \u201ctreat\u201d instead of \u201chelp\u201d to obtain more authoritative results). In some examples, the suggestions may include an explanation of why the query suggestion is being provided (e.g., to increase get accuracy of results) and/or an estimated improvement by adoption of the suggested query alteration (e.g., a percentage improvement in accuracy, reduction in bias, etc.).\n\nExample Bias Detection and/or Compensation of Generalized Bias\n\nFIG. 4is a flow diagram of an example process400usable to detect and/or compensate for generalized bias. The process400may be performed by a computing device, such as a search engine (e.g., search engine104) or other website or service.\n\nAt operation402, the computing device receives a search query from a client device via one or more communication connections (e.g., communication connections220). Responsive to the search query, at operation404, the computing device obtains search results based on one or more ranking algorithms. The search results may include multiple entries. Each entry corresponds to a web page, document, or other content source. At operation406, the computing device detects potential bias in one or more of the search result entries. The potential bias may be detected in a variety of ways. In some examples, the bias may be detected based on terms used in captions of the search result entries. For instance, bias may be detected based on authoritativeness (or lack thereof) of captions of the entries, or based on the use of alarming terms in the captions of the entries. Additionally or alternatively, bias may be detected based upon content of the underlying web pages, documents, or other content sources to which the respective search result entries correspond. For instance, the computing device may compare content of each of the entries of the search to one or more authoritative sources (e.g., Cochrane reviews, Physicians' Desk Reference, Manufacturer Service Manual, etc.) and may identify entries that differ substantively from the one or more authoritative sources as being potentially biased entries.\n\nAt operation408, the computing device modifies the search results to generate modified search results that at least partially compensate for the potential bias in the at least one entry. The modifications to the search results may include, for example, those discussed above with respect to the ranking algorithm(s)118and/or the result modification operation126inFIG. 1. Moreover, in some examples, the result modification may be performed at least in part by the search customizer226illustrated inFIG. 2. There are many ways in which search results can be modified to compensate for bias. For instance, the computing device may, at operation410, replace an entry that includes a first term in the caption with another entry which has substantively similar content to the entry and has a caption that includes a second term which has previously been determined to be more likely to be associated with authoritative content than the first term. Additionally or alternatively, modifying the search results may include, at operation412, appending an annotation to the search results with an indication of the one or more potentially biased entries. As discussed in further detail below, the annotation may take the form of a flag or visual indicator (see e.g.,FIG. 5A) presented in association with each of the one or more potentially biased entries. Each visual indicator may include a confidence level that the entry is biased (e.g., 70% chance the entry is biased) and/or a degree of bias for the entry (e.g., this entry is moderately biased). In examples in which a search query relates to diagnosing a condition, the annotation may take the form of one or more normative base rates (see e.g.,FIG. 5B), which indicate a likelihood of the condition given one or more symptoms. Additionally or alternatively, modifying the search results may comprise, at operation414, reordering the search results based on the potential bias. For instance, the computing device may rank the obtained search results based on potential bias (e.g., by ranking algorithms118), and modify the search results based on the potential bias (e.g., by reordering the search results to present entries having least potential bias earlier in the modified search results). These and other modifications of the search results are possible to compensate for bias or potential bias of the search results.\n\nAt operation416, the computing device outputs the modified search results via the one or more communication connections for presentation at the client device. Additionally or alternatively, the computing device may output search results obtained responsive to the search query, without modification, for presentation at the client device. Additional details of example techniques for presenting modified and/or original search results are provided below with reference toFIG. 6A-FIG. 6D.\n\nAfter outputting the results (modified and/or original) for presentation to the user, at operating418, the computing device may receive user input (e.g., click-through data, views, etc.) responsive to the search results. The computing device may examine the user input to determine whether the user input indicates any bias in the modified search results. For instance, if the user quickly scrolled down and selected the third search result, the computing device may attempt to determine why the user selected the third search result and what actions the user took after selecting the third search result. In doing so, the computing device may determine whether a caption of the third search result included any terms or images that were unique to the third result (i.e., were not included in the captions of other entries of the search results). If so, the computing device may determine whether the unique term(s) or images are associated with accurate/authoritative results (e.g., by comparison to one or more authoritative sources). If not, the computing device may, at operation420, update the ranking algorithms to account for potential bias in the search result in future searches. For instance, the computing device may down sample the potentially biased search result so that will appear later in future search results.\n\nAdditionally or alternatively, the computing device may identify the term/image as a potentially biasing term/image and may store the term/image in a list of potentially biased terms in memory. Additionally or alternatively, the computing device may update a belief model for the user to indicate that the user holds a particular belief about the term/image. Additionally or alternatively, the computing device may determine whether the user's search actions were escalated based upon viewing the third result. If so, then the computing device may determine that the unique term/image may be an alarming term and may store the term as such in memory.\n\nExample Annotation of Potential Bias\n\nAs discussed above with reference to operation412, in some examples search results may be modified by appending an annotation indicating that one or more entries of the search results are potentially biased.FIGS. 5A and 5Billustrate example annotations of search results to indicate potential bias.\n\nFIG. 5Aillustrates an example search results page500in which search results have been modified by annotating the entries with a visual indicator of potential bias. For instance, in the illustrated example, a user submitted a search query502of \u201cchest pain\u201d via a search box of a website www.searchsite.com. The search query was submitted and the website returned search results including three entries504,506, and508. A visual indicator is presented in association with each of the one or more potentially biased entries. In this example, the visual indicator for each entry includes a symbol indicating a degree of bias and a textual description of the potential bias. For instance, entry504includes an example visual indicator denoted by symbol \u201cX\u201d (indicating a \u201cwarning\u201d of potential bias) and a textual description describing a likelihood or confidence level that the content corresponding to the entry is biased (e.g., \u201c82% chance page contains biased content\u201d). Entry506includes an example visual indicator denoted by a triangle symbol (indicating a \u201ccaution\u201d of potential bias) and a textual description describing a degree or extent of bias the corresponding content is likely to have (e.g., \u201cpage may contain up to 50% biased content\u201d). Entry508includes an example visual indicator denoted by a circle symbol (indicating a \u201cneutral\u201d rating) and a textual description describing why the corresponding content received a neutral rating (e.g., because the \u201cpage appears objective/authoritative\u201d).\n\nFIG. 5Billustrates another example search results page510in which search results have been modified by appending an annotation to the search results, the annotation including one or more normative base rates512. In this example, the computing device may determine that the query, \u201cchest pain,\u201d corresponds to a diagnostic query. In response to determining that the query is a diagnostic query, the computing device may annotate the search results with one or more normative base rates, which indicate a likelihood of a condition given one or more symptoms. In the illustrated example, the normative base rates include a list of conditions (e.g., muscle fatigue, injury, indigestion, heart attack, and other) and their respective likelihoods given the symptom of \u201cchest pain.\u201d The normative base rates may be based on an authoritative source of statistics related to the subject of diagnosis. The normative base rates provide an indication to the user that certain entries of the search results may be biased. That is, by informing the user of the objective likelihood of certain conditions, the user is able to determine that results that relate to a very unlikely condition are likely biased (are inaccurate and/or are not representative of the most likely conditions).\n\nExample Presentation of Multiple Search Results\n\nAs discussed above, in some examples multiple sets of search results (e.g., modified search results that compensate for bias and original search results that do not) may be output for presentation to the user at a client device. The two sets of search results may be output concurrently (blended or separately) or sequentially (e.g., the user may toggle between them).\n\nFIGS. 6A-6Dillustrate additional details of process400, including example techniques for obtaining search results (operation404) and outputting search results (operation416). As shown in the example ofFIG. 6A, obtaining search results (operation404) includes, at operation602, obtaining first search results responsive to a search query based at least in part on a first ranking algorithm and, at operation604, obtaining second search results responsive to the search query based at least in part on a second ranking algorithm. The second ranking algorithm in this example is different from the first ranking algorithm. In some examples, either the first ranking algorithm or second ranking algorithm takes into account veracity of the search results, and the other of the first ranking algorithm or the second ranking algorithm does not. In other examples, one of the first ranking algorithm or the second ranking algorithm may weight popularity of results more heavily than veracity of the results, and the other of the first ranking algorithm or the second ranking algorithm may weight veracity of results more heavily than popularity of the results.\n\nProcess400then may proceed through the other operations outlined with reference toFIG. 4, or may skip to operation416to output results. In either case, as shown in exampleFIG. 6A, outputting search results (operation416) may include, at operation606, concurrently outputting both the first search results and the second search results in a composite format for presentation concurrently. The composite format may include two separate, discrete sets of results for concurrent display (as shown inFIG. 6B), two or more discrete sets of results for sequential display (as shown inFIG. 6C), or a blended format in which entries of the first set of search results are interleaved with entries of the second set of search results (as shown inFIG. 6D).\n\nAlternatively, the computing device (e.g., search engine) may output first and second sets of search results sequentially upon request of the user. In that case, outputting the search results (operation416) may include, at operation608, outputting one of the first or second sets of search results and, at operation610, outputting a control usable to view the other of the first and second search results. The control may be output for presentation along with the first or second set of search results. At operation612, the computing device may receive user input from a client device of the user indicating selection of the control. Responsive to receipt of the user input, the computing device may, at operation614, output the other of the first or second search results for presentation at the client device. In this way, the search engine may allow the user to toggle between the first and second sets of search results. While two sets of search results are described in the preceding examples, in other examples three or more sets of search results may be obtained and output for presentation.\n\nFIG. 6Bis a user interface616illustrating an example composite format in which multiple discrete sets of search results are configured for concurrent display. Specifically, a first set of search results618is presented in a top portion of the user interface616, and a second set of search results620are presented in a bottom portion of the user interface616. The first and second sets of search results each include a \u201csee more\u201d control usable to view additional results from the respective set. By selecting the \u201csee more\u201d control for the first set of search results618, the first set of results will be expanded to show additional results and the second set of results may be collapsed, and vice versa. In this example, the first set of search results618comprises a set of \u201coriginal results\u201d which are obtained according to a traditional, popularity based ranking algorithm and are unmodified, and the second set of search results620in this example comprises a set of \u201cmodified results\u201d which are obtained using a ranking algorithm that takes into account veracity of the results and/or compensates for bias. However, in other examples, the first and second search results may be obtained in other ways and/or using different ranking algorithms.\n\nFIG. 6Cis a user interface622illustrating an example composite format in which multiple discrete sets of search results are configured for sequential presentation at a client device of the user. In this example, a control624is output with multiple sets of search results to allow the user to toggle between the multiple sets of search results at the client side. The control624is illustrated inFIG. 6Cas a row of tabs disposed across a top of the interface622within a browser window. However, in other examples, the control may comprise a radio button, a hyper link, a menu, an icon, or any other mechanism that may be used to switch from one view to another. In the illustrated example, user selection of a tab of the control624causes presentation of results associated with the selected tab. The interface622illustrates a view in which a first tab626entitled \u201cbasic\u201d is selected and a set of popularity based search results are presented. Upon user selection of a second tab630entitled \u201cunbiased,\u201d the view toggles to present a second interface630which presents a second set of search results that compensates for bias by taking into account veracity of the search results. Using the control usable624the user is able to toggle between the first search results and the second search at the client device.\n\nFIG. 6Dis a user interface632illustrating an example composite format in which multiple sets of search results are blended together to for concurrent presentation. Specifically, as shown in interface632entries from the original search results (noted by the dashed arrows) and modified search results (noted by the dotted arrows) are interleaved together to provide the blended results. Entries that are common to both the original and modified results are noted by dot-dash arrows. The entries in the blended results may be interleaved in an alternating fashion (first modified results, first original result, second modified result, second original result, etc.), or the ranking algorithms used for the original results and the modified results may be merged (e.g., rankings for each entry under both algorithms may be averaged) and presented in an order based on the merged ranking.\n\nExample Bias Detection and/or Compensation of Individualized Bias\n\nFIG. 7is a flow diagram of an example process700usable to detect and/or compensate for individualized bias. The process700may be performed by a computing device, such as a search engine (e.g., search engine104) or other website or service.\n\nAt operation702, the computing device receives a search query from a client device of a user via one or more communication connections (e.g., communication connections220). At operation704, the computing device determines a type or \u201csubject\u201d of the search query. The subject of the search query may be determined by the terms used in the search query and/or the way in which the query is framed (i.e., the format or structure of the query). Certain terms may be associated with certain types of queries. For instance, terms like \u201cdiagnose,\u201d \u201ctreat,\u201d \u201csymptom,\u201d \u201ccause,\u201d \u201chelp,\u201d \u201cfix,\u201d \u201ctroubleshoot,\u201d etc. may be associated with diagnostic subjects. Moreover, diagnostic queries are typically framed in predictable ways (e.g., will action A treat condition X, is symptom B caused by condition Y, does action C fix problem Z, etc.). As another example, terms having to do with religion or politics may be associated with opinion based subjects. As yet another example, names of actors, movies, artists, songs, etc. may be associated with entertainment related subjects. The computing device may compare the received search query to one or more lists of terms, previous queries, and/or common query formats to determine the subject of the query. Based on the terms used and the format/structure of the search query, the computing device may determine the subject of the search query (e.g., whether the subject is diagnostic in nature, opinion based, entertainment related, etc.)\n\nAt operation706, if the subject of the query has not been determined with sufficient certainty (e.g., a confidence threshold has not been met), then the computing device may, at operation708, attempt to verify the subject matter of the query by, for example, asking the user to indicate a type of query. This verification may be in the form of one or more questions presented to the user to clarify the nature of the query (e.g., \u201care you attempting to diagnose a condition?,\u201d \u201cby \u2018Madonna\u2019 do you mean the religious personage, the singer, the artwork?\u201d, etc.). Based on the responses received from the user, the computing device may be able to discern the subject of the query. This verification708may be repeated until the subject of the query is determined to the threshold confidence level.\n\nIf, at operation706, the subject of the query is determined to a sufficient level of certainty (i.e., the confidence threshold is met), the computing device may at, operation710, to determine whether user preferences exist regarding the type of ranking algorithm to apply. For instance, the computing device may check to see whether the user has manifest an explicit or implicit (e.g., based on prior search behavior) preference for veracity of search results, validation of the user's beliefs, etc. User preferences may be absolute (e.g., always apply a veracity based ranking algorithm to present the most accurate search results, or never use a veracity based ranking algorithm), or may be conditional (e.g., use a veracity based algorithm for diagnostic queries, but use a popularity based algorithm for all other query subjects).\n\nAt operation712, the computing device selects a ranking algorithm to apply, from among multiple available ranking algorithms, based at least in part on the subject of the query and/or the user's preference(s). The multiple available ranking algorithms may include at least a first ranking algorithm that is based at least in part on veracity of content of the search results, and a second ranking algorithm that does not take into account veracity of content of the search results. In some examples, when the subject of the search query is determined at operation704to be diagnostic, at operation710the computing device selects the first ranking algorithm, which takes into account veracity. In contrast, in such examples, when the subject of the search query is determined at operation704to be opinion based (e.g., politics, religion, entertainment, etc.), at operation710the computing device selects the second ranking algorithm, which does not take into account veracity. In other examples, other ranking algorithms may be selected depending on the subject of the search query. In some examples, multiple ranking algorithms may be selected.\n\nOnce one or more ranking algorithms have been selected, at operation714, the computing device may obtain search results based at least in part on the selected ranking algorithm(s). If multiple ranking algorithms were selected in operation712, then multiple sets of search results may be obtained at operation714.\n\nIn some examples, at operation716, the computing device may determine one or more beliefs of the user relevant to the search query. The computing device may determine the beliefs of the user that are relevant to the search query by reference to a belief model of the user (e.g., belief model128inFIG. 1). The belief information may be obtained by explicit information provided by the user or by inference based on search history of the user or client device, click-through history of the user or client device, and/or browser history of the user or client device. As discussed above, belief information may be obtained prior to receiving the search query (e.g., when the user accesses a search engine or web site, creates an account, opens or initializes an application, etc.) or after receiving the search query (e.g., in response to one or more questions or prompts soliciting information from the user of the client device).\n\nAt operation718, the computing device may generate modified search results (e.g., modified search results136) for the user based at least in part on the search query and the one or more beliefs of the user. In other examples, operation718may be performed contemporaneously with obtaining the search results, such that custom search results are generated for the user without first preliminary search results. In some examples, entries of the modified/custom search results may be ordering to compensate for one or more biases of the user. Additionally or alternatively, in some examples, the results may be further modified/customized based\n\nAt operation720, the computing device may transmit the search results (original/preliminary and/or modified/custom) to the client device for presentation to the user.\n\nThe processes300,400, and700are described with reference to the architecture100and system200ofFIGS. 1 and 2for convenience and ease of understanding. However, the processes300,400, and700are not limited to being performed using the architecture100and system200. Moreover, the architecture100and system200are not limited to performing the processes300,400, and700.\n\nThe processes300,400, and700are illustrated as collections of blocks in logical flow graphs, which represent sequences of operations that can be implemented in hardware, software, or a combination thereof. In the context of software, the blocks represent computer-executable instructions stored on one or more computer-readable storage media that, when executed by one or more processors, perform the recited operations. Generally, computer-executable instructions include routines, programs, objects, components, data structures, and the like that perform particular functions or implement particular abstract data types. The order in which the operations are described is not intended to be construed as a limitation, and any number of the described blocks can be combined in any order and/or in parallel to implement the processes. In some embodiments, one or more blocks of the process may be omitted entirely. Moreover, the processes300,400, and700may be combined in whole or in part. For instance, the process300of query reformulation may be performed in combination with one or more of the result modification processes400and/or700.\n\nThe various techniques described herein may be implemented in the context of computer-executable instructions or software, such as program modules, that are stored in computer-readable storage and executed by the processor(s) of one or more computers or other devices such as those illustrated in the figures. Generally, program modules include routines, programs, objects, components, data structures, etc., and define operating logic for performing particular tasks or implement particular abstract data types.\n\nOther architectures may be used to implement the described functionality, and are intended to be within the scope of this disclosure. Furthermore, although specific distributions of responsibilities are defined above for purposes of discussion, the various functions and responsibilities might be distributed and divided in different ways, depending on circumstances.\n\nSimilarly, software may be stored and distributed in various ways and using different means, and the particular software storage and execution configurations described above may be varied in many different ways. Thus, software implementing the techniques described above may be distributed on various types of computer-readable media, not limited to the forms of memory that are specifically described.\n\nConclusion\n\nIn closing, although the various embodiments have been described in language specific to structural features and/or methodological acts, it is to be understood that the subject matter defined in the appended representations is not necessarily limited to the specific features or acts described. Rather, the specific features and acts are disclosed as example forms of implementing the claimed subject matter.\n\n",
            "length": 75520
        },
        {
            "patent_id": "10938201",
            "text": "DETAILED DESCRIPTION OF THE INVENTION\n\nWith reference toFIG. 1, an aircraft A includes an electrical installation1having a high-voltage power source2connected to a user apparatus5via an electrical link8comprising an electrical protection device3associated with the electrical link8.\n\nThe power source2is furthermore linked to the user apparatus5by a current return line6.\n\nThe high-voltage power source2supplies a DC voltage HV of the order of +/\u2212270 volts DC, +/\u2212540 volts DC or other voltage level.\n\nThe aircraft A furthermore comprises a conductive structure (not shown) that is formed by a metal or other conductive element of the aircraft and is at a reference potential to form the ground50(visible inFIG. 4).\n\nWith reference toFIGS. 2 and 3, the electrical link comprises a conductor4surrounded by an insulating cover4a(for example a plastic sleeve) and the electrical protection device3comprises a part arranged on the insulating cover4aof the electrical conductor4, and a part formed of electronic devices that are for example arranged in a secure housing12.\n\nThe part arranged on the insulating cover4acomprises a conductive sleeve7surrounded by an insulating cover7a. The conductive sleeve7surrounds the insulating cover4aof the conductor4.\n\nThe part situated in the housing12(seeFIG. 2) comprises:\n\na circuit breaker9linked to the high-voltage power source2and that, when it is commanded in this respect, makes it possible to interrupt the supply of the signal HV to the user apparatus5. In a known manner, the circuit breaker9operates as a switch that, when activated, opens and thus shuts off the conductor4.\n\na current generator10; and\n\na detection module11for detecting a current leak out of the conductor4.\n\nA current leak occurs when the electrical link8is damaged. For example, a leak may result from contact of the conductor4with the conductive sleeve7when the insulating cover4ais damaged or form contact of the conductor4with an element external to the electrical link when the two insulating covers4aand7aare damaged. A current leak may lead to the creation of electric arcs between the conductor and the conductive structure of the aircraft A or with another conductor set to a potential different from the conductor or with the current return line6if the latter is at a potential different from ground.\n\nThe electrical link8advantageously extends from the housing12and all the way to the user apparatus5(only a portion of the electrical link has been shown inFIG. 4).\n\nAs shown inFIG. 4, the current generator10provides the function of current-biasing the conductive sleeve7by injecting a direct current Ig on the conductive sleeve7at a current injection point30that is, for example, situated at the upstream end (housing12side) of the electrical link8.\n\nThe current generator is preferably limited in terms of voltage, with a voltage limit chosen so as not to be hazardous to humans, typically less than 50 volts. This preferred option makes it possible to add an additional degree of protection for humans.\n\nThe sign of the bias current Ig is preferably the reverse of that of the voltage HV delivered by the high-voltage power source2, in order to speed up the detection of a current leak by the detection module11. For example, the bias current Ig delivered by the current generator20is \u22121 A for a voltage HV of 540 volts DC delivered by the high-voltage power source2.\n\nThe detection module11(seeFIG. 4) comprises a shunt40used to measure the current Ir tapped off at the tap-off point31of the conductive sleeve7, a comparator42connected to the shunt40, and a microcontroller43linking the output of the comparator to the input of the circuit breaker9. The microcontroller thus receives an output signal of the comparator42and supplies a command signal to the circuit breaker9.\n\nThe shunt40, with a known resistance Rshunt, is connected at a first terminal to the current tap-off point31of the conductive sleeve7, and at a second terminal to ground50. The current tap-off point31is, for example, situated at the downstream end (on the user apparatus5side) of the electrical link8.\n\nThe comparator42is connected, at a first input, to the first terminal of the shunt40via an electrical link termed detection line51, and at a second input to a DC voltage generator42asupplying a voltage, termed reference voltage, Vref.\n\nThe comparator42compares the voltage Ur in the detection line51, which voltage is proportional to the current Ir measured via the shunt40(Ur=Ir\u00d7Rshunt), with the reference voltage Vref that is proportional to a reference current Iref (Vref satisfies Vref=Rshunt\u00d7Iref). The output signal of the comparator may adopt two states. The first state is indicative of a current leak out of the electrical link8. The second state is indicative of an absence of a current leak out of the electrical link8.\n\nIn the event of an absence of a current leak out of the conductor4, Ir=Ig and Ur=Ig\u00d7Rshunt<Vref. Reference is then made to a voltage Ur in the detection line51that is nominal.\n\nBy way of example (seeFIG. 4), in a scenario involving Boolean logic in which the first state of the output signal of the comparator42corresponds to the state 1 and the second state of the output signal corresponds to the state 0, and if the voltage HV is positive and the bias current Ig is negative, the negative input of the comparator is connected to the voltage generator42aand the positive input is connected to the detection line51such that the output signal of the comparator changes to 1 when Ur becomes greater than Vref.\n\nThe microcontroller43is configured to monitor a change of state of the output signal of the comparator42, so as to detect a current leak out of the electrical link8. If the microcontroller detects a change of state of the output signal from the second state to the first state, it sends a command signal to the circuit breaker containing instructions to activate said circuit breaker so as to cut off the high-voltage supply HV to the user apparatus5.\n\nAs an option, a low-pass filter (active, passive or hybrid)41is arranged between the comparator42and the shunt40so as to eliminate interference signals that may be present on the conductive sleeve7and that could falsify the results of the comparisons performed by the comparator42.\n\nWith reference toFIG. 5, what is shown is an example of the evolution of the signals HV and Ur over time when, starting from a time T1, the electrical link8exhibits a fault (scenario of a fault with/breakage of the insulating cover4aor of a fault with/breakage of the insulating covers4aand7a), and a situation occurs whereby current leaks out of the conductor4.\n\nIn these examples, the high-voltage power source2produces a positive voltage HV, and Ir is negative, and:\n\nHV=540 V,\n\nIg=\u22121 A,\n\nRshunt=10 ohms,\n\nVref=\u22125 V, i.e. a fault is detected as soon as the leakage current Ir reaches 0.5 A.\n\nWith consideration to these data, Ur nominal is equal to \u221210 V.\n\nFrom a time0until the time T1, there is no current leak out of the electrical link8, and the voltage Ur in the detection line51is constant and bounded by Vref as an upper bound.\n\nAt the time T1, the conductor4for example enters into contact with the conductive sleeve7(fault with the insulating cover4a), and the voltage Ur in the detection line51increases until it exceeds the reference voltage Vref at the time T2. From this moment, the output signal of the comparator42changes from its second state to its first state, and the microcontroller43receiving the signal from the comparator42sends a command signal to the circuit breaker containing instructions to activate the circuit breaker. At the time T3, the circuit breaker9is activated and the supply of electric power is interrupted: the voltage HV becomes zero. The period between the times T2and T3, of the order of a few milliseconds, corresponds to the reaction time of the electronic devices forming the detection module11, and to the reaction time of the circuit breaker9.\n\nThe electrical protection device3reacts as soon as a current leak is detected, to interrupt the supply of electric power after a brief reaction time of the electronic circuits. The current-biased conductive sleeve7thus forms a detector that is capable of detecting damage to the electrical link8. The fast cutting off (a few milliseconds) of the electric power prevents damage to the surrounding materials through a thermal effect, and also prevents the injection of current into the surrounding materials and the propagation of the high voltage HV into other cables/conductors.\n\nThe characteristics of the shunt40are chosen such that the voltage Ur in the detection line51, before T1inFIG. 5, is lower than the voltage limit of the current generator10supplying Ig. Contact of the biased conductive sleeve7(when the electrical link8does not exhibit a fault) with a human is not hazardous, as the conductive sleeve7is not at an electrical potential that is hazardous to humans.\n\nIn a variant embodiment of the invention shown inFIGS. 6 and 7, the electrical protection device3furthermore comprises a test module60that makes it possible to check the correct operation of the detection module11. The test module60consists of a central unit61associated with a first switch62and with a second switch63. The central unit61commands the switching of the switches62and63.\n\nThe first switch62is connected to the injection point30(either directly or indirectly). In the latter case, it is for example connected to the output of the current generator10, and is able to switch to a first non-connected terminal or to a second terminal linked to a current generator64supplying a current, termed test current, Itest, having the same sign as the bias current Ig and chosen such that the value of the test current Itest plus the value of the bias current Ig leads to the output signal of the comparator42changing to its first state.\n\nFor example, picking up on the example given with reference toFIG. 5, Itest=0.55 A.\n\nThe second switch63is connected to the output of the microcontroller43and is able to switch to a first terminal linked to the central unit61, such that only the latter receives the command signal from the microcontroller43, or to a second terminal linked to the input of the circuit breaker9, such that it is only the circuit breaker that receives the command signal from the microcontroller43.\n\nThe second switch63is connected to the output of the microcontroller43of the detection module11and is able to switch to two different terminals:\n\na first terminal linked to the microcontroller61of the test module; or\n\na second terminal linked to the input of the circuit breaker9.\n\nThe central unit61is configured to control the switches62,63and to implement a test step at regular intervals and for a predetermined duration.\n\nWhen the test step is not implemented, the central unit61commands the switching of the first switch62to its first terminal and the switching of the second switch63to its second terminal.\n\nWhen the central unit61implements the test step:\n\nthe first switch62switches to its second terminal so as to force the input of the detection module (the current injected into the sleeve is forced to exceed the high reference value Iref1) and the second switch63switches to its first terminal so as not to activate the circuit breaker9while the test is being implemented; and\n\nthe central unit61receives the command signal from the microcontroller43and monitors a change of state of said signal from the second state to the first state, and is thus able to check whether the detection module11is operative, that is to say that it has indeed generated a signal containing instructions to activate the circuit breaker9. If, at the end of a predetermined test time, the detection module11does not have the signal to activate the circuit breaker, the central unit61emits an alert intended for an operator, who is able to choose to maintain the supply of electric power until the end of the aircraft's flight, for example, or to bring about the interruption of the supply of electric power by actuating a manual circuit breaker (not shown) in the aircraft's cockpit, for example. An operator will have to repair the detection module11in order for the system for securing the supply of electric power to become operational again.\n\nIn the above description, current return line6is understood to mean either a return conductor or a current return network. If the current return line6is a conductor set to a voltage different from that of the conductive structure of the aircraft, then an electrical protection device such as described above will have to be associated with the current return line6in order to secure the current return.\n\nIn one variant that is not shown, in order for the conductive sleeve7and its insulating cover7ato form electrical shielding (which also performs the role of shielding against lightning or electromagnetic pulses) for the electrical conductor4and its insulating cover4a, a first limiting element is arranged between the current generator10and the injection point30, and a second limiting element is arranged between the tap-off point31and the shunt40. The two limiting elements are transient-voltage suppression diodes with a breakdown voltage greater than Vref in terms of absolute value.\n\nThe invention has been described for the purpose of protecting the transmission of electric power via an electrical link of an electrical installation1on an aircraft A. However, the invention is applicable to any other type of vehicle, for example a boat or an automobile.\n\nThe invention has been described, in particular through the example illustrated inFIG. 5, for a positive voltage HV and a negative bias current. It is within the scope of those skilled in the art to modify the invention so as to take account of other parameters (positive voltage HV, positive or negative bias current).\n\nWhile at least one exemplary embodiment of the present invention(s) is disclosed herein, it should be understood that modifications, substitutions and alternatives may be apparent to one of ordinary skill in the art and can be made without departing from the scope of this disclosure. This disclosure is intended to cover any adaptations or variations of the exemplary embodiment(s). In addition, in this disclosure, the terms \u201ccomprise\u201d or \u201ccomprising\u201d do not exclude other elements or steps, the terms \u201ca\u201d or \u201cone\u201d do not exclude a plural number, and the term \u201cor\u201d means either or both. Furthermore, characteristics or steps which have been described may also be used in combination with other characteristics or steps and in any order unless the disclosure or context suggests otherwise. This disclosure hereby incorporates by reference the complete disclosure of any patent or application from which it claims benefit or priority.\n\n",
            "length": 14848
        },
        {
            "patent_id": "10938338",
            "text": "DETAILED DESCRIPTION\n\nExemplary embodiments described, shown, and/or disclosed herein are not intended to limit the claims, but rather, are intended to instruct one of ordinary skill in the art as to various aspects of the invention. Other embodiments can be practiced and/or implemented without departing from the scope and spirit of the claimed invention. As an example, the description below discusses panels primarily with respect to photovoltaic solar panels. Nonetheless, the term panel can mean a window, such as a skylight, a mirror, or any plane for which the cleaning system can be utilized.\n\nApplicant hereby incorporates by reference in its entirety U.S. application Ser. No. 13/567,205, filed by Inventor Georg Eitelhuber on Aug. 6, 2012. The application was published as US 2013/0037051 A1 on Feb. 14, 2013. The language and embodiments of the application will not be repeated herein for the purpose of brevity.\n\nAn exemplary embodiment is shown schematically inFIG. 1. The track and cleaning system (100) can have a brush assembly (102) with at least one rotatable brush (103) having a rotational axis. A drive can be configured to translate the brush assembly parallel to the rail (101). A carriage assembly (104) for translating the brush assembly can have a pivot, which can be configured to allow pivoting of the rotational axis in a plane parallel to the rails and the rotational axis, which is also parallel to panel (106). The pivoting action can further be aided by a trailing assembly (105), which can have another pivot that is slidably attached to the brush assembly. Directional arrow shows the direction of travel of the brush and carriage assemblies. The angle, \u03b8, between the direction of travel and the rotational axis of the brushes can be less than ninety degrees when the duster is operating.\n\nFIGS. 2A-2Cshow a cleaning system in an initial configuration, as well as two operational configurations. As the carriage assembly (204) is driven across the panel, the pivots in the carriage (204) and trailing (205) assemblies can allow the longitudinal axis of the brushes to rotate parallel to the panel. Initially, the brushes can overhang the trailing assembly. This distance of overhang can decrease as the brushes rotate into an operating position, as shown inFIGS. 2B and 2C.\n\nAn advantageous aspect of the system is the way the device can slide up into an angled position that can allow the top end to lead. This can allow dust and debris to fall forward and away from the brush-panel interface. The unique roller support on the bottom of the brush assembly can allow the system to be supported by a cart, always directly over the rail.\n\nLeading the top edge of the brush assembly can dramatically increase effectiveness of the cleaning in several ways. The dust at the top need not be re-brushed many times on the way down after being dislodged, as can happen if the brush is constrained vertically.\n\nFurther, the bristle pattern on the brushes can be straight instead of spiral. This can facilitate flicking the dust and debris from the surface, rather than grinding them across the panel surface by lateral relative velocity of a bristle spiral. Yet because of the nonperpendicular angle, with respect to the direction of travel, dust and debris can still be directed towards the bottom edge more rapidly.\n\nIn an embodiment, the solar panel cleaning system can incorporate one or more support assemblies to support the brushes. The system can also have one or more motors to operate the rotatable brushes and/or a drive wheel. The rotatable brushes can move across a panel in a direction, for example as shown by the directional arrows inFIGS. 1-4, and/or in the opposite direction. Additionally, the rotatable brushes can pivot to a certain degree across the surface.\n\nWhen in a run position, i.e. an operational position, the angle \u03b8 between the direction of travel, defined by the direction of the track, and the rotational axis, defined by the longitudinal axis of one or more of the brushes, can be between zero and 180 degrees. When the brushes are in rest position, the rotational axis can be perpendicular to the rails. Further, the rotatable brushes can be rotated counter-clockwise and/or clockwise from a rest position to reach an operating position.\n\nThe embodiment ofFIG. 2Cshows an operating configuration where the angle has been defined by the length of the brush assembly. Once the sliding member reaches the end of the brush assembly, the trailing assembly can be pulled by the driven carriage assembly at a defined angle. The embodiment ofFIG. 2Bshows an operating configuration in which the brush assembly is allowed to pivot until an equilibrium angle is achieved. The mechanical advantages in the embodiments are manifold. For example, the tracks can have very large tolerances for lateral distance apart, and the brush can simply find its own angle comfortably. For straight brushes, conversely, such changes in the lateral angle would result in the system pulling itself apart. Exemplary operating angles can include 30 to 80 degrees, 40 to 75 degrees, 50 to 70 degrees, 55 to 65 degrees, and/or less than 60 degrees.\n\nFIGS. 3A and 3Bare an exploded view and a substantially assembled depiction of the carriage assembly (300). The carriage can have one or more drive wheels. In the exemplary embodiment ofFIG. 3, drive wheel (301) can be attached to motor (303) by means of a coupling (304). Rollers (302) can form a triangular shape when assembled so as to hold tight to a rail with a triangular cross section. The term roller herein can mean wheel, caster, bearing, roller bearing, and/or other elements. The carriage can further have a pivot (305) mounted to a pivot plate (306) or be otherwise mounted.\n\nThe triangular shape of the rollers is shown in the exemplary cleaning system (400) ofFIG. 4. As can be seen, carriage assembly (402) can be configured to hold tight onto rails (401), which have a triangular cross section. A closer view of the cross section of the rail, including hollow areas and exemplary internal support structures, can be seen inFIG. 5.\n\nReferring again toFIG. 4, a brush assembly can frame rotatable brushes (403) and be attached to pivots (404). The brush assembly can thereby be attached to the drive wheel, via the carriage assembly, and to the trailing assembly (408), via a slidable pivot (407). The rotatable brushes can include a shaft and a sweeping member. The sweeping member can be made of bristles comprising bristles, such as hair, plastic, and/or metal bristles. Alternatively, the sweeping member can be made of foam and/or sponge.\n\nA brush assembly motor (406) can be used to actuate and/or rotate the rotatable brushes about their longitudinal axes. The shaft can be coupled to a drive transmission. The brushes can rotate about their axes such that the part of the brush in contact with the surface moves in the same direction as the direction of travel of the brush assembly and/or in the opposite direction. The carriage assembly can be coupled to a drive motor (405). Although not shown inFIG. 4, the trailing assembly can also be coupled to a drive motor, for example to facilitate returning the brushes to a perpendicular orientation for storing and/or to facilitate reversing the direction of travel. Alternatively, the brushes can be configured to return to a perpendicular orientation, with respect to the track, simply by continuing to rotate the brushes as the drive motor translates the brush assembly to its starting position opposite the directional arrow.\n\nIn an embodiment, there can be one motor to operate the rotatable brushes. The brushes can be configured to rotate in the same direction synchronously or in two different directions through the use of gears. Gearing can be utilized to rotate different brushes of a multi-brush assembly at different speeds. In an embodiment there may be two or more motors. In such an embodiment, several brushes can be individually operated by different motors.\n\nFIG. 5shows a rail having a triangular cross section. The shape and internal support features can be achieved an extrusion process. The rail can be, for example, extruded aluminum. Such is advantageous as the rail can be very stiff and rigid. Moreover, such a rail can have a closed configuration and can have good bending moment characteristics.\n\nFIGS. 6A-6Cshow alternative rail configurations that can be advantageously fabricated from cold rolling processes. Such materials as cold rolled steel provide many benefits. The rails can be long, without seams, and very strong. Cold rolled rails can be very stiff, and ordinary cold rolled steel can be utilized inexpensively. Moreover, cold rolled metal can further act as a load bearing member to provide structural support, for example, to an entire photovoltaic array. The grey rectangles inFIGS. 6A-6Crepresent roller positions around the rail. An advantage to the triangular cross sections inFIGS. 5 and 6is that the number of rollers for maintaining the carriage and/or trailing assemblies on the rails is minimized.\n\nFIG. 7shows a track system (700) that can include a rail (701). Rollers (702) can be utilized on all three of the planar faces of the rail. The rail can include intermittent supports (703) and fasteners (704), such as bolts and/or rivets. The intermittent supports can be, though need not be, attached to a solar panel support or to a solar panel directly. If made for the track alone, and not a load bearing member, intermittent supports can be used to attach the track to the main support. The supports can provide additional stiffness to the cross section of the rail by joining the two parts of the rail intermittently.\n\nAlthough an advantage of the present system is in the minimization of the number of rollers and/or roller assemblies required, it may be advantageous and/or convenient to use rollers on four or five faces of a track.FIGS. 8A and 8Bshows contemplated rail configurations, as well as various roller positions.\n\nTwo alternative embodiments are shown inFIGS. 9 and 10.FIG. 9shows an external rail configuration with a triangular cross section. A drive wheel is represented by the large rectangle on top and two sets of complimentary rollers are represented by the rectangles on either side of the rail. InFIG. 10, the rollers are internal to the rail. An internal rail can be beneficial is it can be more compact than an external rail. Moreover, as will be shown, an internal rail can allow a brush system to be disposed close to the plane of a surface by mounting the rail such that the top of the channel is flush with the surface to be swept.\n\nFIGS. 11 and 12show two configurations for positioning a solar panel cleaning system (1100) close to the surface to be cleaned, for example a solar panel surface (1101). A primary roller (1102), i.e. a load-bearing drive wheel, is positioned on top of a triangular rail (1104). The top surface of the rail has been disposed in the plane of the solar panel surface. Complementary rollers (1103) are shown on either side of the triangular rail. InFIG. 12, the rollers can be more compactly configured within the channel of the rail, dramatically reducing the profile of the cleaning system. Further, the configuration can allow the rail and cleaning system to be disposed very close the surface to be cleaned. It can be advantageous to include means for dust abatement, such as a flexible hood or bristles along the top of the channel and/or egress apertures along the bottom of the channel Additionally, a skirt around the pivot and sliding members can be utilized to prevent dust and debris from falling into the channel. Further, the assembly components can be disposed in a housing to seal them from dust and dirt.\n\nThe system can further include a self-cleaning system configured to automatically clean the one or more rotatable brushes. The system can be integrated with a housing for the brushes or merely attached to an edge of a panel array. A self-cleaning member can include a stiff brush, a row of rake-like tines, a bar, or other effective elements against which the rotating brushes can pass while rotating and thereby eliminate excess dust and debris buildup.\n\nInFIG. 13, similar toFIG. 12, the rollers (1302) can be disposed within a channel. The internal rail can be adhered to the solar panels (1301), for example with resin (1303).FIG. 14additionally shows a pivot arm (1404) for attaching to a brush assembly. Rubber strips (1406) with circular cross sections can be attached inside support frame members (1405) having a C-shaped cross section. The members can be used to mount the solar panels (1401). The support frame can be bolted to a main array. The support frame can be part of the main array, for example as an integral part of an extrusion. As shown inFIG. 14, a panel can be inserted straight (where there is clearance), and then can be let down to an angle of tilt. This can crush the rubber strips, and can thereby cause a locking force on the panels. The other end of the panel can be held down either by a resin stick, by small clamp, and/or by an adhesive. Conversely, the rubber bits can be attached to the panels themselves for substantially the same effect.\n\nFIGS. 15-19show various embodiments of a photovoltaic array. InFIG. 15, solar panels (1501) can be mounted to support structures (1503) and track (1502). The track can be an internal rail, such as a channel, or an external rail. As shown inFIG. 16, the cleaning system (1602) can be centrally mounted to a pivot connected to a carriage assembly which utilizes only a central track. Alternatively, trailing roller assemblies can be incorporated along the top, bottom, or top and bottom edges of the array of solar panels (1601), similar to embodiments shown inFIGS. 1-4.\n\nReferring toFIGS. 17 and 18, the array of solar panels (1701) can include a track (1702) that is off center. Here also, the track can be an internal rail, such as a channel, or an external rail. The carriage and pivot (1804) can be utilized alone or in combination with other roller assemblies to translate and pivot the cleaning system (1803).\n\nFor a centrally located track, it can be advantageous to incorporate a trailing assembly with its own drive or motor, or to incorporate a rolling resistance to facilitate pivoting. A motor can be integrated with the pivot to produce a power-actuated pivot.\n\nInFIG. 19, solar panels (1901) can be supported by and mounted to rails (1905). Brush assembly (1903) can be translated and operated by carriage assembly (1902). The translation, orientation, and support of the brush can further be facilitated by a trailing roller assembly (1904). As shown above, the carriage and the trailing assembly can have substantially similar roller configurations.\n\nThe cleaning system can further include a monitoring device to determine whether a cleaning is required. The device can include a meter of the output of the solar panels. Alternatively, the device can include sensor system for measuring the efficiency and/or effectiveness of the photovoltaic elements.\n\nThe monitoring device can be in communication with a control device. The control device can be configured to activate the cleaning system. The control device can be configured to send a signal indicating the status and/or the need for cleaning a panel. Additionally, the control device can be configured to send a signal indicating a fault or error in the array system, including in the cleaning system.\n\nDetails of one or more embodiments are set forth in the accompanying drawings and description. Other features, objects, and advantages will be apparent from the description, drawings, and claims. Although a number of embodiments of the invention have been described, it will be understood that various modifications may be made without departing from the spirit and scope of the invention. It should also be understood that the appended drawings are not necessarily to scale, presenting a somewhat simplified representation of various features and basic principles of the invention.\n\n",
            "length": 16128
        },
        {
            "patent_id": "PP32877",
            "text": "NOT A COMMERCIAL WARRANTY\n\nThe following detailed description has been prepared to solely comply with the provisions of 35 U.S.C. \u00a7 112, and does not constitute a commercial warranty, (either expressed or implied), that the present variety will, in the future, display the botanical, pomological or other characteristics as set forth herein. Therefore, this disclosure may not be relied upon to support any future legal claims, including but not limited to breach of warranty of merchantability, or fitness for any particular purpose, which is directed, in whole, or in part, to the present variety.\n\nDETAILED DESCRIPTION\n\nReferring more specifically to the pomological and botanical details of this new and distinct variety of apple tree, the following has been observed from third-generation trees grown in Vantage, Wash. 98950, USDA Hardiness Zone 7A, and asexually reproduced in Ephrata, Wash., USDA Hardiness Zone 6B. All color references are from The R.H.S. Colour Chart by The Royal Horticulture Society.\n\nThe closest known antecedent to \u2018Regal D17-121\u2019 is the Apple Tree named \u2018Regal D5-100\u2019 (U.S. Plant Pat. No. 31,503P3), a variety ofMalus domesticafrom a controlled cross of Huaguan x Honeycrisp. The following are some characteristics to distinguish \u2018Regal D17-121\u2019 from \u2018Regal D5-100\u2019. \u2018Regal D17-121\u2019 is slightly taller and wider than the \u2018Regal D5-100\u2019. The \u2018Regal D17-121\u2019 leaf is larger, both in length and width, than the leaf of the \u2018Regal D5-100\u2019. The \u2018Regal D17-121\u2019 produces a larger fruit than that of the \u2018Regal D5-100\u2019.Tree:Tree type.\u2014Upright and spreading. Spur type and tip bearer.Tree vigor.\u2014Considered moderate on the high side.Tree shape.\u2014Generally inverted cone.Tree height.\u2014About 10.0 feet.Tree width.\u2014About 4.0 feet.Hardiness.\u2014Considered hardy for the current region grown in.Fruit productivity.\u2014Considered moderate (from about 75 bins to about 80 bins per acre).Trunk:Trunk diameter.\u2014About 37.9 millimeters when measured at a height of about 30 centimeters above the ground.Bark texture.\u2014Generally smooth.Bark color.\u2014From the Grey-Brown group (RHS N199C).Trunk lenticels.\u2014About eleven per nine square centimeters of growth.Trunk lenticel width.\u2014From about 0.9 millimeters to about 1.9 millimeters.Trunk lenticel length.\u2014From about 2.2 millimeters to about 5.1 millimeters with an average of about 4.2 millimeters.Trunk lenticel color.\u2014From the Yellow-White group (RHS 158D).Trunk lenticel shape.\u2014Generally flat.Branches:Scaffold branches:Scaffold branch diameter.\u2014From about 10.8 millimeters to about 14.8 millimeters with an average of about 13.3 millimeters as measured at 10 centimeters from trunk.Scaffold branch color.\u2014From the Greyed-Brown group (RHS N199D).Scaffold branch texture.\u2014Generally smooth.Scaffold branch angle.\u2014About 80 degrees to about 90 degrees as trained.Scaffold branch lenticels.\u2014About seven per nine square centimeters of growth.Scaffold branch lenticel shape.\u2014Generally flat.Scaffold branch lenticel length.\u2014From about 2.5 millimeters to about 3.5 millimeters with an average of about 3.0 millimeters.Scaffold branch lenticel width.\u2014From about 0.9 millimeters to about 1.6 millimeters with an average of about 1.3 millimeters.Scaffold branch lenticel color.\u2014From the White group (RHS N155D).Two-year-old fruiting branches:Two-year-old branch diameter.\u2014From about 5.8 millimeters to about 9.9 millimeters with an average of about 7.9 millimeters.Two-year-old branch texture.\u2014Generally smooth.Two-year-old branch pubescence.\u2014None.Two-year-old branch color.\u2014From the Grey-Brown group (RHS N199D).Two-year-old branch lenticel numbers.\u2014Present and averaging about five lenticels per running centimeter of branch.Two-year-old branch lenticel shape.\u2014Generally round.Two-year-old branch lenticel diameter.\u2014From about 0.7 millimeters to about 1.1 millimeters.Two-year-old branch lenticel color.\u2014From the White group (RHS N155D).Two-year-old branch spur development:Two-year-old branch spur length.\u2014From about 0.9 centimeters to about 3.6 centimeters.Two-year-old branch spur width.\u2014From about 3.8 millimeters to about 4.9 millimeters.Two-year-old branch bud shape.\u2014Generally elliptical in shape.Two-year-old branch spur bud length.\u2014From about 8.3 millimeters to about 10.7 millimeters with an average of about 9.4 millimeters.Two-year-old branch spur bud diameter.\u2014From about 4.0 millimeters to about 5.8 millimeters with an average of about 4.7 millimeters.Two-year-old branch tip bud length.\u2014From about 7.8 millimeters to about 9.2 millimeters with an average of about 8.6 millimeters.Two-year-old branch bud scale color.\u2014From the Greyed-Purple group (RHS N186C).Two-year-old branch spur pubescence.\u2014Light in density over about 60% of surface.Two-year-old branch spur pubescence color.\u2014From the White group (RHS N155D).Two-year-old branch crotch angle.\u2014From about 20 degrees to about 40 degrees.2018 branches:2018branch texture.\u2014Generally smooth.2018branch length.\u2014From about 21.5 centimeters to about 69.5 centimeters with an average of about 48.0 centimeters.2018branch diameter at midpoint.\u2014From about 6.0 millimeters to about 7.9 millimeters with an average of about 7.0 millimeters.2018branch pubescence.\u2014Light in density over about 80% of surface.2018branch pubescence color.\u2014From the White group (RHS N155D).2018branch color.\u2014From the Brown group (RHS 200D).2018branch lenticels.\u2014Present and averaging about 17 per running centimeter of branch.2018branch lenticel shape.\u2014Generally round.2018branch lenticel diameter.\u2014From about 0.6 millimeters to about 1.3 millimeters.2018branch lenticel color.\u2014From the White group (RHS N155D).2018branch internode length.\u2014From about 29.6 millimeters to about 41.8 millimeters with an average of about 35.9 millimeters.Bloom (flowers):First bloom date.\u2014Apr. 27, 2018.Full bloom date.\u2014Apr. 30, 2018.Bud shape.\u2014Generally elliptical.Bud length.\u2014From about 8.3 millimeters to about 10.7 millimeters with an average of about 9.4 millimeters.Bud diameter.\u2014From about 4.0 millimeters to about 5.8 millimeters with an average of about 4.7 millimeters.Vegetative bud support size.\u2014About 4.5 millimeters.Bud color.\u2014From the Greyed-Purple group (RHS N186C).Number of blossoms per cluster.\u2014From about 4 to 6, mostly 5.Blossom size.\u2014Generally considered medium-large.Flower depth.\u2014About 11.2 millimeters.Diameter when fully open.\u2014From about 39.0 millimeters to about 49.0 millimeters with an average of about 43.8 millimeters.Petal count.\u2014About 5 per blossom.Petal shape.\u2014Generally oval with rounded tip.Petal arrangement.\u2014Free.Petal width.\u2014From about 13.7 millimeters to about 16.9 millimeters with an average of about 15.5 millimeters.Petal length.\u2014From about 17.3 millimeters to about 22.0 millimeters with an average of about 20.1 millimeters.Petal margin.\u2014Generally smooth.Petal color.\u2014Upper surface from the White group (RHS N155D). Undersurface highlights from the Red-Purple group (RHS N66D).Position of the stigmas relative to anthers.\u2014Anthers directly below and surrounding the stigma.Stamen number.\u2014From about 20 to about 22, mostly 20.Stamen filament length.\u2014From about 5.5 millimeters to about 7.6 millimeters with an average of about 6.8 millimeters.Stamen filament color.\u2014From the White group (RHS 155C).Stamen anthers shape.\u2014Generally kidney shaped.Stamen anthers width.\u2014From about 1.4 millimeters to about 2.0 millimeters with an average of about 1.7 millimeters.Stamen anthers length.\u2014From about 1.7 millimeters to about 2.4 millimeters with an average of about 2.1 millimeters.Stamen anthers color.\u2014From the Yellow-Orange group (RHS 18C).Stamen anthers pollen.\u2014Generally moderate in density.Stamen anthers pollen color.\u2014From the Greyed-Orange group (RHS 166C).Pistil length.\u2014From about 10.5 millimeters to about 11.9 millimeters with an average of about 11.2 millimeters. Styles are fussed an average of about 4.6 millimeters from base.Pistil color.\u2014From the Yellow-Green group (RHS 145A).Pubescence.\u2014No.Stigma number.\u2014About 5 or 6 per blossom.Stigma shape.\u2014Generally clubbed.Stigma color.\u2014From the Yellow-Orange group (RHS 20A).Sepal number.\u2014About 5 per blossom.Sepal shape.\u2014Generally lanceolate.Sepal shape at tip.\u2014Generally acuminate.Sepal shape at base.\u2014Generally truncate.Sepal length.\u2014From about 8.9 millimeters to about 12.2 millimeters with an average of about 10.5 millimeters.Sepal width.\u2014From about 3.6 millimeters to about 4.6 millimeters with an average of about 4.1 millimeters.Sepal margin.\u2014Generally smooth.Sepal color.\u2014From the Yellow-Green group (RHS 146B).Sepal pubescence.\u2014Moderate in density over 100% of both surface areas.Sepal pubescence color.\u2014From the White group (RHS 155C).Peduncle length.\u2014From about 18.8 millimeters to about 25.1 millimeters with an average of about 23.3 millimeters.Peduncle diameter at midpoint.\u2014From about 1.2 millimeters to about 1.7 millimeters with an average of about 1.6 millimeters.Peduncle color.\u2014From the Yellow-Green group (RHS 144A).Peduncle pubescence.\u2014Moderate in density over 100% surface area.Peduncle pubescence color.\u2014From the White group (RHS 155C).Thalmus depth.\u2014From about 4.1 millimeters to about 6.2 millimeters with an average of about 5.0 millimeters.Thalmus color.\u2014From the Yellow-Green group (RHS 147A).Thalmus pubescence.\u2014Moderate in density over 100% surface area.Thalmus pubescence color.\u2014From the White group (RHS 155C).Leaves:Shape.\u2014Generally acute.Upper texture.\u2014Generally smooth and leathery.Lower texture.\u2014Generally smooth with veins protruding.Upper sheen.\u2014generally high gloss.Lower sheen.\u2014Generally medium gloss under the pubescence.Pubescence.\u2014Lightly moderate on about 100% of lower surface area.Pubescence color.\u2014From the White group (RHS 155C).Length.\u2014From about 9.4 centimeters to about 12.0 centimeters with an average of about 10.54 centimeters.Width.\u2014From about 5.3 centimeters to about 6.4 centimeters with an average of about 6.1 centimeters.Leaf profile cross-section.\u2014About 0.3 millimeters.Margin.\u2014Mostly crenate with occasional bi-serrate.Tip.\u2014Generally acuminate.Leaf blade tip length.\u2014About 0.8 centimeters.Base.\u2014Generally rounded (obtuse).Upper blade color.\u2014From the Green group (RHS 137A).Lower blade color.\u2014From the Green group (RHS 138B).Mid vein.\u2014Generally present on lower surface.Mid vein pubescence.\u2014Generally light on over 100% of surface.Mid vein pubescence color.\u2014White Group (RHS 155B).Mid vein diameter at midpoint.\u2014From about 1.2 millimeters to about 1.6 millimeters with an average of about 1.4 millimeters.Mid vein color.\u2014From the Green group (RHS 139D).Stipules.\u2014Present and about two per petiole.Stipules shape.\u2014Curved linear.Stipules length.\u2014From about 5.1 millimeters to about 11.9 millimeters with an average of about 9.2 millimeters.Stipules width.\u2014From about 1.4 millimeters to about 1.8 millimeters with an average of about 1.6 millimeters.Stipules color.\u2014Upper and Lower Stipules from the Green group (RHS 137A).Stipules pubescence.\u2014None.Petiole shallow grove upper surface.\u2014Generally present full length and from about 0.1 millimeters to about 0.2 millimeters in depth.Petiole length.\u2014From about 2.7 centimeters to about 3.7 centimeters with an average of about 3.2 centimeters.Petiole diameter at midpoint.\u2014From about 1.5 millimeters to about 1.9 millimeters with an average of about 1.7 millimeters.Petiole color.\u2014From the Green group (RHS 139D) with the basal end highlighted from the Greyed-Orange group (RHS N170D).Petiole pubescence.\u2014Generally light in density over all surface areas.Petiole pubescence color.\u2014From the White group (RHS 155C).Petiole attitude.\u2014Generally flat with blades rolled upwards from about 20 degrees to about 45 degrees with no drupe.Fruit:Form.\u2014Considered mostly oblate, occasionally flat round.Size.\u2014Considered medium with normal crop level.Weight.\u2014About 295 grams.Equatorial diameter.\u2014From about 8.2 centimeters to about 9.2 centimeters with an average of about 8.8 centimeters.Axis diameter.\u2014From about 7.1 centimeters to about 8.3 centimeters with an average of about 7.8 centimeters.Stem.\u2014Generally not clubbed.Stem length.\u2014From about 17.5 millimeters to about 25.1 millimeters with an average of about 23.8 millimeters.Stem diameter at midpoint.\u2014From about 2.5 millimeters to about 3.3 millimeters with an average of about 2.8 millimeters.Stem color.\u2014From the Yellow-Green group (RHS 145D).Stem pubescence.\u2014Present in moderate density covering about 100% of surface.Stem pubescence color.\u2014From the Green-White group (RHS 157D).Stem cavity shape.\u2014Generally acute.Stem cavity lipped.\u2014No.Stem cavity russet.\u2014None observed.Stem cavity russet color.\u2014None observed.Stem cavity width.\u2014From about 29.2 millimeters to about 33.7 millimeters with an average of about 31.0 millimeters.Stem cavity depth.\u2014From about 15.1 millimeters to about 23.6 millimeters with an average of about 19.6 millimeters.Basin cavity ribbed.\u2014No.Basin cavity sides.\u2014Considered smooth, cone shaped.Basin cavity width.\u2014From about 27.2 millimeters to about 34.8 millimeters with an average of about 31.4 millimeters.Basin cavity depth.\u2014From about 9.9 millimeters to about 18.0 millimeters with an average of about 13.8 millimeters.Basin cavity eye.\u2014Considered mostly erect with occasional reflexed tips.Basin cavity eye pubescence.\u2014Downy present both upper and lower surface at moderately light density.Basin cavity eye pubescence color.\u2014From the White group (RHS 155D).Basin cavity eye shape.\u2014Considered closed with occasional reflexed tips.Skin appearance.\u2014Mostly flush with light molting and light bloom. No russet.Skin color.\u2014Flush area from the Red group (RHS 46A), Background from the Yellow group (RHS 8B).Skin thickness.\u2014Considered thin. About 0.1 millimeters.Skin texture.\u2014Generally smooth and melting.Skin lenticels.\u2014Generally not prominent.Skin lenticels shape.\u2014Generally round ranging from about 0.4 millimeters to about 0.6 millimeters in diameter.Skin lenticels number.\u2014About 6 per square centimeter.Skin lenticels color.\u2014From the Yellow group (RHS 8B).Core position.\u2014Considered distant from stalk.Core line position.\u2014Considered basal clapping.Core shape.\u2014Generally ovate.Core length.\u2014From about 30.0 millimeters to about 31.8 millimeters with an average of about 31.4 millimeters.Core diameter.\u2014From about 40.8 millimeters to about 43.8 millimeters with an average of about 42.6 millimeters.Cell tufted.\u2014No.Cell shape.\u2014Generally obovate.Cell length.\u2014From about 14.1 millimeters to about 16.5 millimeters with an average of about 15.1 millimeters.Cell width.\u2014From about 7.0 millimeters to about 10.7 millimeters with an average of about 8.8 millimeters.Cell wall-to-wall distance.\u2014From about 3.3 millimeters to about 4.3 millimeters with an average of about 3.8 millimeters.Tube shape.\u2014Considered cone shaped and closed to core.Tube stamen position.\u2014Considered basal.Tube axis.\u2014Considered abaxial and closed.Seed number.\u2014From about 1 to 2, mostly 2.Seed shape.\u2014Considered mostly acute with an occasional obtuse.Seed length.\u2014From about 8.1 millimeters to about 9.1 millimeters with an average of about 8.7 millimeters.Seed width.\u2014From about 5.4 millimeters to about 5.9 millimeters with an average of about 5.2 millimeters.Seed depth(wall to wall).\u2014From about 2.5 millimeters to about 3.2 millimeters with an average of about 2.9 millimeters.Seed color.\u2014From the Greyed-Orange group (RHS 177A).Flesh.\u2014Very firm, crisp, melting, and moderately sub-acid. No browning observed following 2 hours of cutting. Flavor is more honey-like than apple.Flesh color.\u2014From the Yellow group (RHS 11D).Aroma.\u2014Very light apple-like.Date of harvest maturity.\u2014Sep. 5, 2018.Maturity pressure.\u201423.8 pounds.Maturity starch.\u20143.0.Maturity soluble solids.\u201415.4 brix %.Maturity malic acid.\u20146.14 grams per liter.Maturity ph.\u20143.84.Keeping quality.\u2014Up to about 6 months in common storage.Productivity.\u2014Considered moderate (from about 75 bins to about 80 bins per acre).Pollination.\u2014Any diploid apple of the same bloom season.Use.\u2014Desert. Excellent eating quality that is snappy, juicy, sweet with very good acid balance and melting skin.Disease and insect resistance.\u2014Considered to be susceptible to all insects and diseases found in the region of Central Washington. Fruit does not exhibit any physiological disorders on the tree nor during storage for the duration of normal storage lengths.\n\nAlthough the new variety of apple tree possesses the described characteristics when grown under the ecological conditions prevailing in Vantage, Wash., in the south-central part of Washington state, it should be understood that variations of the usual magnitude and characteristics incident to changes in growing conditions, fertilization, pruning and pest control as well as horticultural management practices are to be expected.\n\n",
            "length": 16640
        }
    ]
}